{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"tcn.ipynb","provenance":[{"file_id":"1DzrxJryMaSxDk7H8KWjUbegw3NTcvmrP","timestamp":1619953123299}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w8iuzT_JZHok","executionInfo":{"status":"ok","timestamp":1619986932741,"user_tz":-330,"elapsed":970,"user":{"displayName":"Sejal Bhalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd83T8nE5o6zGLINWWUfr_S_8fE_h_SM_LXr0WGQ=s64","userId":"12680971253671894594"}},"outputId":"771ecc76-d78c-40e6-dd72-e3a843d7b18c"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sun May  2 20:22:12 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   54C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yZgbbQIyqI-y"},"source":["!pip install keras-tcn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nWV9bu_aZkIp","executionInfo":{"status":"ok","timestamp":1619986981229,"user_tz":-330,"elapsed":38589,"user":{"displayName":"Sejal Bhalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd83T8nE5o6zGLINWWUfr_S_8fE_h_SM_LXr0WGQ=s64","userId":"12680971253671894594"}},"outputId":"e002a3e4-cf7a-4373-8da7-02d585b15314"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_bKKPLxDZwPZ"},"source":["import os\n","import numpy as np\n","import pickle\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from scipy import signal, spatial, stats\n","from fastdtw import fastdtw\n","from scipy.signal import find_peaks\n","import pywt\n","import warnings\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import tensorflow.keras as keras\n","from tensorflow.keras.layers import Input, Dense, Conv1D, Conv2D, MaxPooling2D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n","from tensorflow.keras.models import Model\n","from sklearn.preprocessing import OneHotEncoder\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.losses import CategoricalCrossentropy, BinaryCrossentropy\n","from tensorflow.keras.metrics import Accuracy, Precision, Recall\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","import pickle\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","import seaborn as sns\n","from sklearn.model_selection import KFold\n","from tcn import TCN, tcn_full_summary"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qD164iAxZ4SH"},"source":["os.chdir('/content/drive/My Drive/Weave/Earables Project/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"au-ujDWxaVMt"},"source":["sub = 's7'\n","X_new = pickle.load(open('Study-3 Data/preprocessed_data/'+sub+'_X.pkl', 'rb'))\n","y_new = pickle.load(open('Study-3 Data/preprocessed_data/'+sub+'_y.pkl', 'rb'))\n","X = pickle.load(open('Final Experiments/raw_data/'+sub+'_X.pkl', 'rb'))\n","y = pickle.load(open('Final Experiments/raw_data/'+sub+'_y.pkl', 'rb'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JgYDrLy6pp9H","executionInfo":{"status":"ok","timestamp":1619986992395,"user_tz":-330,"elapsed":2075,"user":{"displayName":"Sejal Bhalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd83T8nE5o6zGLINWWUfr_S_8fE_h_SM_LXr0WGQ=s64","userId":"12680971253671894594"}},"outputId":"2e2bf5d0-12bd-44d0-f5e6-67793308b042"},"source":["np.unique(y_new.label)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '20',\n","       '22', '23', '24', '25', '26', '27', '28', '2l', '4', '41', '42',\n","       '43', '44', '45', '46l', '46r', '5', '6', '7', '9',\n","       'baseline_metro', 'baseline_sitting', 'baseline_walking', 'eating',\n","       'speaking'], dtype=object)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"-jxQu2rOpJgQ"},"source":["Static data"]},{"cell_type":"code","metadata":{"id":"JU233-XnlN3j"},"source":["train_inds = dict(zip(range(5), [[], [], [], [], []]))\n","test_inds = dict(zip(range(5), [[], [], [], [], []]))\n","kf = KFold(n_splits=5, shuffle=True, random_state = 45)\n","for label in np.unique(y.label):\n","    label_df = y[y.label == label]\n","    central_inds = np.array([idx for idx in label_df.index if idx%5 ==0])\n","    for fold, (tr, te) in enumerate(kf.split(central_inds)):\n","        tr_inds = sum([list(range(tr_i, tr_i+5)) for tr_i in central_inds[tr]], [])\n","        te_inds = sum([list(range(te_i, te_i+5)) for te_i in central_inds[te]], [])\n","\n","        train_inds[fold].extend(tr_inds)\n","        test_inds[fold].extend(te_inds)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jF7odgpapL37"},"source":["Baseline (Sitting), Eating, Speaking"]},{"cell_type":"code","metadata":{"id":"jj4A1Gh_pSps"},"source":["train_inds_new = dict(zip(range(5), [[], [], [], [], []]))\n","test_inds_new = dict(zip(range(5), [[], [], [], [], []]))\n","for label in ['baseline_sitting', 'eating', 'speaking']:\n","    label_df = y_new[y_new.label == label]\n","    central_inds = np.array([idx for idx in label_df.index if idx%5 ==0])\n","    for fold, (tr, te) in enumerate(kf.split(central_inds)):\n","        tr_inds = sum([list(range(tr_i, tr_i+5)) for tr_i in central_inds[tr]], [])\n","        te_inds = sum([list(range(te_i, te_i+5)) for te_i in central_inds[te]], [])\n","\n","        train_inds_new[fold].extend(tr_inds)\n","        test_inds_new[fold].extend(te_inds)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AsavYPSErBOc"},"source":["Merge data"]},{"cell_type":"code","metadata":{"id":"HQI05oLJgV-n"},"source":["def split(train_inds, test_inds, train_inds_new, test_inds_new, fold, binary=False):\n","    tr_inds, te_inds = train_inds[fold], test_inds[fold]\n","    tr_inds_new, te_inds_new = train_inds_new[fold], test_inds_new[fold]\n","    X_train = np.vstack((X[tr_inds], X_new[tr_inds_new]))\n","    X_test = np.vstack((X[te_inds], X_new[te_inds_new]))\n","    y_train = np.concatenate((y.loc[tr_inds].label.to_numpy(), y_new.loc[tr_inds_new].label.to_numpy()))\n","    y_test = np.concatenate((y.loc[te_inds].label.to_numpy(), y_new.loc[te_inds_new].label.to_numpy()))\n","\n","    #Encode labels\n","    ohe = OneHotEncoder()\n","    if binary:\n","        for i in range(len(y_train)):\n","            if y_train[i] in ['baseline_sitting', 'eating', 'speaking']:\n","                y_train[i] = 'other'\n","            else:\n","                y_train[i] = 'au'\n","        for i in range(len(y_test)):\n","            if y_test[i] in ['baseline_sitting', 'eating', 'speaking']:\n","                y_test[i] = 'other'\n","            else:\n","                y_test[i] = 'au'\n","    ohe.fit(y_train.reshape(-1, 1))\n","    y_train = ohe.transform(y_train.reshape(-1, 1)).toarray()\n","    y_test = ohe.transform(y_test.reshape(-1, 1)).toarray()\n","\n","    # Transpose X\n","    X_train = np.transpose(X_train, [0, 2, 1])\n","    X_test = np.transpose(X_test, [0, 2, 1])\n","    return X_train, y_train, X_test, y_test, ohe"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0hbyUTc4rz3A","executionInfo":{"status":"ok","timestamp":1619978782945,"user_tz":-330,"elapsed":954,"user":{"displayName":"Sejal Bhalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd83T8nE5o6zGLINWWUfr_S_8fE_h_SM_LXr0WGQ=s64","userId":"12680971253671894594"}},"outputId":"1e7a6f3d-6ff3-4942-bacb-c58273429870"},"source":["X_train, y_train, X_test, y_test = split(train_inds, test_inds, train_inds_new, test_inds_new, fold, binary=False)\n","print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(9640, 100, 12) (2410, 100, 12) (9640, 2) (2410, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qe5vCEgIvwWT","executionInfo":{"status":"ok","timestamp":1619978788775,"user_tz":-330,"elapsed":1475,"user":{"displayName":"Sejal Bhalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd83T8nE5o6zGLINWWUfr_S_8fE_h_SM_LXr0WGQ=s64","userId":"12680971253671894594"}},"outputId":"14013fb1-989c-4538-8690-a8be4bdea2c2"},"source":["ohe.categories_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array(['au', 'other'], dtype=object)]"]},"metadata":{"tags":[]},"execution_count":127}]},{"cell_type":"code","metadata":{"id":"QRnSK5vDyVPR"},"source":["def build_model(input_shape, n_classes, activation='sigmoid'):\n","    input = Input(shape=input_shape)\n","    x = TCN(return_sequences=False, nb_filters=64)(input)\n","    # x = TCN(return_sequences=False, nb_filters=128)(x)\n","    x = Dense(n_classes, activation=activation, name='output')(x)\n","\n","    model = Model(input, x)\n","    # model.summary()\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6cBsDIeVy4wf","executionInfo":{"status":"ok","timestamp":1619988332425,"user_tz":-330,"elapsed":1056073,"user":{"displayName":"Sejal Bhalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd83T8nE5o6zGLINWWUfr_S_8fE_h_SM_LXr0WGQ=s64","userId":"12680971253671894594"}},"outputId":"b4466395-433c-4481-956c-b721cb14caf1"},"source":["for fold in range(5):\n","    print('------------------------ Fold {}/5'.format(fold+1)+' ------------------------')\n","    #Split data\n","    X_train, y_train, X_test, y_test, ohe = split(train_inds, test_inds, train_inds_new, test_inds_new, fold, binary=False)\n","    print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n","\n","    #Define Variables\n","    batch_size = 32\n","    n_classes = 34\n","    input_shape = (100, 12)\n","\n","    #Define model\n","    model = build_model(input_shape, n_classes)\n","\n","    #Compile\n","    model_name = 'tcn_separate_classes_sub_{}_fold_{}'.format(sub, fold+1)\n","    optimizer = Adam(learning_rate=0.001)\n","    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics='accuracy')\n","\n","    checkpoint = ModelCheckpoint('Final Experiments/checkpoint/null_class/{}.h5'.format(model_name), monitor='val_loss', verbose=1, mode='min',save_best_only=True)\n","    earlystopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1)\n","    reducelr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, min_lr=0.000001)\n","\n","    #Fit\n","    history = model.fit(X_train, y_train,\n","                    validation_data=(X_test, y_test),\n","                    batch_size=batch_size,\n","                    epochs=100,\n","                    # workers=4,3\n","                    callbacks=[checkpoint, earlystopping, reducelr],\n","                    shuffle=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["------------------------ Fold 1/5 ------------------------\n","(9640, 100, 12) (2410, 100, 12) (9640, 34) (2410, 34)\n","Epoch 1/100\n","302/302 [==============================] - 5s 11ms/step - loss: 1.4545 - accuracy: 0.0675 - val_loss: 0.1218 - val_accuracy: 0.1905\n","\n","Epoch 00001: val_loss improved from inf to 0.12178, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_1.h5\n","Epoch 2/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.1126 - accuracy: 0.2377 - val_loss: 0.1018 - val_accuracy: 0.3120\n","\n","Epoch 00002: val_loss improved from 0.12178 to 0.10182, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_1.h5\n","Epoch 3/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0947 - accuracy: 0.3539 - val_loss: 0.0916 - val_accuracy: 0.3934\n","\n","Epoch 00003: val_loss improved from 0.10182 to 0.09164, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_1.h5\n","Epoch 4/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0808 - accuracy: 0.4450 - val_loss: 0.0729 - val_accuracy: 0.4834\n","\n","Epoch 00004: val_loss improved from 0.09164 to 0.07291, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_1.h5\n","Epoch 5/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0692 - accuracy: 0.5254 - val_loss: 0.0667 - val_accuracy: 0.5324\n","\n","Epoch 00005: val_loss improved from 0.07291 to 0.06667, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_1.h5\n","Epoch 6/100\n","302/302 [==============================] - 3s 9ms/step - loss: 0.0629 - accuracy: 0.5693 - val_loss: 0.0613 - val_accuracy: 0.5747\n","\n","Epoch 00006: val_loss improved from 0.06667 to 0.06131, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_1.h5\n","Epoch 7/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0546 - accuracy: 0.6289 - val_loss: 0.0582 - val_accuracy: 0.6095\n","\n","Epoch 00007: val_loss improved from 0.06131 to 0.05819, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_1.h5\n","Epoch 8/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0491 - accuracy: 0.6759 - val_loss: 0.0569 - val_accuracy: 0.6544\n","\n","Epoch 00008: val_loss improved from 0.05819 to 0.05695, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_1.h5\n","Epoch 9/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0431 - accuracy: 0.7285 - val_loss: 0.0462 - val_accuracy: 0.7307\n","\n","Epoch 00009: val_loss improved from 0.05695 to 0.04620, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_1.h5\n","Epoch 10/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0392 - accuracy: 0.7524 - val_loss: 0.0429 - val_accuracy: 0.7145\n","\n","Epoch 00010: val_loss improved from 0.04620 to 0.04294, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_1.h5\n","Epoch 11/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0336 - accuracy: 0.8008 - val_loss: 0.0415 - val_accuracy: 0.7328\n","\n","Epoch 00011: val_loss improved from 0.04294 to 0.04147, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_1.h5\n","Epoch 12/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0298 - accuracy: 0.8304 - val_loss: 0.0410 - val_accuracy: 0.7627\n","\n","Epoch 00012: val_loss improved from 0.04147 to 0.04096, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_1.h5\n","Epoch 13/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0279 - accuracy: 0.8473 - val_loss: 0.0308 - val_accuracy: 0.8332\n","\n","Epoch 00013: val_loss improved from 0.04096 to 0.03075, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_1.h5\n","Epoch 14/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0252 - accuracy: 0.8665 - val_loss: 0.0376 - val_accuracy: 0.7763\n","\n","Epoch 00014: val_loss did not improve from 0.03075\n","Epoch 15/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0237 - accuracy: 0.8712 - val_loss: 0.0261 - val_accuracy: 0.8535\n","\n","Epoch 00015: val_loss improved from 0.03075 to 0.02607, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_1.h5\n","Epoch 16/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0214 - accuracy: 0.8758 - val_loss: 0.0297 - val_accuracy: 0.8373\n","\n","Epoch 00016: val_loss did not improve from 0.02607\n","Epoch 17/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0190 - accuracy: 0.9079 - val_loss: 0.0238 - val_accuracy: 0.8797\n","\n","Epoch 00017: val_loss improved from 0.02607 to 0.02384, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_1.h5\n","Epoch 18/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0165 - accuracy: 0.9228 - val_loss: 0.0270 - val_accuracy: 0.8784\n","\n","Epoch 00018: val_loss did not improve from 0.02384\n","Epoch 19/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0149 - accuracy: 0.9300 - val_loss: 0.0351 - val_accuracy: 0.8349\n","\n","Epoch 00019: val_loss did not improve from 0.02384\n","Epoch 20/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0199 - accuracy: 0.9039 - val_loss: 0.0228 - val_accuracy: 0.8776\n","\n","Epoch 00020: val_loss improved from 0.02384 to 0.02284, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_1.h5\n","Epoch 21/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0123 - accuracy: 0.9412 - val_loss: 0.0370 - val_accuracy: 0.8564\n","\n","Epoch 00021: val_loss did not improve from 0.02284\n","Epoch 22/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0210 - accuracy: 0.9164 - val_loss: 0.0187 - val_accuracy: 0.9124\n","\n","Epoch 00022: val_loss improved from 0.02284 to 0.01872, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_1.h5\n","Epoch 23/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0114 - accuracy: 0.9547 - val_loss: 0.0253 - val_accuracy: 0.8780\n","\n","Epoch 00023: val_loss did not improve from 0.01872\n","Epoch 24/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0123 - accuracy: 0.9423 - val_loss: 0.0202 - val_accuracy: 0.9029\n","\n","Epoch 00024: val_loss did not improve from 0.01872\n","Epoch 25/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0103 - accuracy: 0.9556 - val_loss: 0.0260 - val_accuracy: 0.8846\n","\n","Epoch 00025: val_loss did not improve from 0.01872\n","Epoch 26/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0088 - accuracy: 0.9619 - val_loss: 0.0206 - val_accuracy: 0.9104\n","\n","Epoch 00026: val_loss did not improve from 0.01872\n","Epoch 27/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0089 - accuracy: 0.9646 - val_loss: 0.0192 - val_accuracy: 0.9066\n","\n","Epoch 00027: val_loss did not improve from 0.01872\n","Epoch 28/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0093 - accuracy: 0.9578 - val_loss: 0.0213 - val_accuracy: 0.8983\n","\n","Epoch 00028: val_loss did not improve from 0.01872\n","Epoch 29/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0084 - accuracy: 0.9642 - val_loss: 0.0219 - val_accuracy: 0.9174\n","\n","Epoch 00029: val_loss did not improve from 0.01872\n","Epoch 30/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0082 - accuracy: 0.9677 - val_loss: 0.0252 - val_accuracy: 0.8971\n","\n","Epoch 00030: val_loss did not improve from 0.01872\n","Epoch 31/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0102 - accuracy: 0.9577 - val_loss: 0.0217 - val_accuracy: 0.9108\n","\n","Epoch 00031: val_loss did not improve from 0.01872\n","Epoch 32/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0062 - accuracy: 0.9762 - val_loss: 0.0237 - val_accuracy: 0.9158\n","\n","Epoch 00032: val_loss did not improve from 0.01872\n","\n","Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n","Epoch 33/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0035 - accuracy: 0.9927 - val_loss: 0.0107 - val_accuracy: 0.9614\n","\n","Epoch 00033: val_loss improved from 0.01872 to 0.01073, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_1.h5\n","Epoch 34/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0010 - accuracy: 0.9988 - val_loss: 0.0108 - val_accuracy: 0.9606\n","\n","Epoch 00034: val_loss did not improve from 0.01073\n","Epoch 35/100\n","302/302 [==============================] - 3s 10ms/step - loss: 8.5555e-04 - accuracy: 0.9992 - val_loss: 0.0104 - val_accuracy: 0.9651\n","\n","Epoch 00035: val_loss improved from 0.01073 to 0.01041, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_1.h5\n","Epoch 36/100\n","302/302 [==============================] - 3s 10ms/step - loss: 7.0359e-04 - accuracy: 0.9991 - val_loss: 0.0107 - val_accuracy: 0.9622\n","\n","Epoch 00036: val_loss did not improve from 0.01041\n","Epoch 37/100\n","302/302 [==============================] - 3s 10ms/step - loss: 5.9504e-04 - accuracy: 0.9993 - val_loss: 0.0105 - val_accuracy: 0.9606\n","\n","Epoch 00037: val_loss did not improve from 0.01041\n","Epoch 38/100\n","302/302 [==============================] - 3s 10ms/step - loss: 5.3980e-04 - accuracy: 0.9993 - val_loss: 0.0113 - val_accuracy: 0.9622\n","\n","Epoch 00038: val_loss did not improve from 0.01041\n","Epoch 39/100\n","302/302 [==============================] - 3s 10ms/step - loss: 4.8251e-04 - accuracy: 0.9998 - val_loss: 0.0104 - val_accuracy: 0.9639\n","\n","Epoch 00039: val_loss improved from 0.01041 to 0.01039, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_1.h5\n","Epoch 40/100\n","302/302 [==============================] - 3s 10ms/step - loss: 4.2815e-04 - accuracy: 0.9996 - val_loss: 0.0106 - val_accuracy: 0.9643\n","\n","Epoch 00040: val_loss did not improve from 0.01039\n","Epoch 41/100\n","302/302 [==============================] - 3s 10ms/step - loss: 3.8343e-04 - accuracy: 0.9995 - val_loss: 0.0115 - val_accuracy: 0.9610\n","\n","Epoch 00041: val_loss did not improve from 0.01039\n","Epoch 42/100\n","302/302 [==============================] - 3s 9ms/step - loss: 4.2986e-04 - accuracy: 0.9998 - val_loss: 0.0111 - val_accuracy: 0.9647\n","\n","Epoch 00042: val_loss did not improve from 0.01039\n","Epoch 43/100\n","302/302 [==============================] - 3s 10ms/step - loss: 3.2073e-04 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9606\n","\n","Epoch 00043: val_loss did not improve from 0.01039\n","Epoch 44/100\n","302/302 [==============================] - 3s 10ms/step - loss: 3.1678e-04 - accuracy: 0.9997 - val_loss: 0.0106 - val_accuracy: 0.9656\n","\n","Epoch 00044: val_loss did not improve from 0.01039\n","Epoch 45/100\n","302/302 [==============================] - 3s 10ms/step - loss: 2.8035e-04 - accuracy: 0.9997 - val_loss: 0.0114 - val_accuracy: 0.9622\n","\n","Epoch 00045: val_loss did not improve from 0.01039\n","\n","Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n","Epoch 46/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.8664e-04 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9656\n","\n","Epoch 00046: val_loss did not improve from 0.01039\n","Epoch 47/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.5496e-04 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9660\n","\n","Epoch 00047: val_loss did not improve from 0.01039\n","Epoch 48/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.4117e-04 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9660\n","\n","Epoch 00048: val_loss did not improve from 0.01039\n","Epoch 49/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.4793e-04 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9668\n","\n","Epoch 00049: val_loss did not improve from 0.01039\n","Epoch 50/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.4047e-04 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9660\n","\n","Epoch 00050: val_loss did not improve from 0.01039\n","Epoch 51/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.3824e-04 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9660\n","\n","Epoch 00051: val_loss did not improve from 0.01039\n","Epoch 52/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.3669e-04 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9668\n","\n","Epoch 00052: val_loss did not improve from 0.01039\n","Epoch 53/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.3459e-04 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9660\n","\n","Epoch 00053: val_loss did not improve from 0.01039\n","Epoch 54/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.3431e-04 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9668\n","\n","Epoch 00054: val_loss did not improve from 0.01039\n","Epoch 55/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.4966e-04 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9664\n","\n","Epoch 00055: val_loss did not improve from 0.01039\n","\n","Epoch 00055: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n","Epoch 56/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.2081e-04 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9664\n","\n","Epoch 00056: val_loss did not improve from 0.01039\n","Epoch 57/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.1959e-04 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9660\n","\n","Epoch 00057: val_loss did not improve from 0.01039\n","Epoch 58/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.1674e-04 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9660\n","\n","Epoch 00058: val_loss did not improve from 0.01039\n","Epoch 59/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.1570e-04 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9660\n","\n","Epoch 00059: val_loss did not improve from 0.01039\n","Epoch 00059: early stopping\n","------------------------ Fold 2/5 ------------------------\n","(9640, 100, 12) (2410, 100, 12) (9640, 34) (2410, 34)\n","Epoch 1/100\n","302/302 [==============================] - 5s 11ms/step - loss: 1.5591 - accuracy: 0.0730 - val_loss: 0.1211 - val_accuracy: 0.2083\n","\n","Epoch 00001: val_loss improved from inf to 0.12113, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_2.h5\n","Epoch 2/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.1055 - accuracy: 0.2732 - val_loss: 0.0963 - val_accuracy: 0.3461\n","\n","Epoch 00002: val_loss improved from 0.12113 to 0.09628, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_2.h5\n","Epoch 3/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0857 - accuracy: 0.4021 - val_loss: 0.0793 - val_accuracy: 0.4498\n","\n","Epoch 00003: val_loss improved from 0.09628 to 0.07929, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_2.h5\n","Epoch 4/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0721 - accuracy: 0.5079 - val_loss: 0.0739 - val_accuracy: 0.4855\n","\n","Epoch 00004: val_loss improved from 0.07929 to 0.07386, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_2.h5\n","Epoch 5/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0660 - accuracy: 0.5531 - val_loss: 0.0573 - val_accuracy: 0.6141\n","\n","Epoch 00005: val_loss improved from 0.07386 to 0.05731, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_2.h5\n","Epoch 6/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0507 - accuracy: 0.6728 - val_loss: 0.0526 - val_accuracy: 0.6743\n","\n","Epoch 00006: val_loss improved from 0.05731 to 0.05255, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_2.h5\n","Epoch 7/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0445 - accuracy: 0.7252 - val_loss: 0.0580 - val_accuracy: 0.6602\n","\n","Epoch 00007: val_loss did not improve from 0.05255\n","Epoch 8/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0401 - accuracy: 0.7515 - val_loss: 0.0467 - val_accuracy: 0.7207\n","\n","Epoch 00008: val_loss improved from 0.05255 to 0.04668, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_2.h5\n","Epoch 9/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0327 - accuracy: 0.8079 - val_loss: 0.0486 - val_accuracy: 0.7033\n","\n","Epoch 00009: val_loss did not improve from 0.04668\n","Epoch 10/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0302 - accuracy: 0.8264 - val_loss: 0.0450 - val_accuracy: 0.7344\n","\n","Epoch 00010: val_loss improved from 0.04668 to 0.04501, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_2.h5\n","Epoch 11/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0264 - accuracy: 0.8462 - val_loss: 0.0362 - val_accuracy: 0.7992\n","\n","Epoch 00011: val_loss improved from 0.04501 to 0.03624, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_2.h5\n","Epoch 12/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0245 - accuracy: 0.8643 - val_loss: 0.0323 - val_accuracy: 0.8266\n","\n","Epoch 00012: val_loss improved from 0.03624 to 0.03233, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_2.h5\n","Epoch 13/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0209 - accuracy: 0.8885 - val_loss: 0.0300 - val_accuracy: 0.8336\n","\n","Epoch 00013: val_loss improved from 0.03233 to 0.03004, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_2.h5\n","Epoch 14/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0207 - accuracy: 0.8962 - val_loss: 0.0285 - val_accuracy: 0.8448\n","\n","Epoch 00014: val_loss improved from 0.03004 to 0.02853, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_2.h5\n","Epoch 15/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0172 - accuracy: 0.9149 - val_loss: 0.0313 - val_accuracy: 0.8274\n","\n","Epoch 00015: val_loss did not improve from 0.02853\n","Epoch 16/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0176 - accuracy: 0.9124 - val_loss: 0.0276 - val_accuracy: 0.8614\n","\n","Epoch 00016: val_loss improved from 0.02853 to 0.02765, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_2.h5\n","Epoch 17/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0139 - accuracy: 0.9377 - val_loss: 0.0263 - val_accuracy: 0.8722\n","\n","Epoch 00017: val_loss improved from 0.02765 to 0.02631, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_2.h5\n","Epoch 18/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0150 - accuracy: 0.9317 - val_loss: 0.0296 - val_accuracy: 0.8461\n","\n","Epoch 00018: val_loss did not improve from 0.02631\n","Epoch 19/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0138 - accuracy: 0.9344 - val_loss: 0.0258 - val_accuracy: 0.8693\n","\n","Epoch 00019: val_loss improved from 0.02631 to 0.02576, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_2.h5\n","Epoch 20/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0118 - accuracy: 0.9444 - val_loss: 0.0252 - val_accuracy: 0.8680\n","\n","Epoch 00020: val_loss improved from 0.02576 to 0.02521, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_2.h5\n","Epoch 21/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0142 - accuracy: 0.9289 - val_loss: 0.0374 - val_accuracy: 0.8029\n","\n","Epoch 00021: val_loss did not improve from 0.02521\n","Epoch 22/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0123 - accuracy: 0.9437 - val_loss: 0.0219 - val_accuracy: 0.8855\n","\n","Epoch 00022: val_loss improved from 0.02521 to 0.02190, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_2.h5\n","Epoch 23/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0095 - accuracy: 0.9565 - val_loss: 0.0388 - val_accuracy: 0.8141\n","\n","Epoch 00023: val_loss did not improve from 0.02190\n","Epoch 24/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0212 - accuracy: 0.9155 - val_loss: 0.0225 - val_accuracy: 0.8888\n","\n","Epoch 00024: val_loss did not improve from 0.02190\n","Epoch 25/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0099 - accuracy: 0.9524 - val_loss: 0.0193 - val_accuracy: 0.9054\n","\n","Epoch 00025: val_loss improved from 0.02190 to 0.01926, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_2.h5\n","Epoch 26/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0089 - accuracy: 0.9589 - val_loss: 0.0263 - val_accuracy: 0.8751\n","\n","Epoch 00026: val_loss did not improve from 0.01926\n","Epoch 27/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0087 - accuracy: 0.9626 - val_loss: 0.0204 - val_accuracy: 0.9100\n","\n","Epoch 00027: val_loss did not improve from 0.01926\n","Epoch 28/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0085 - accuracy: 0.9659 - val_loss: 0.0194 - val_accuracy: 0.9071\n","\n","Epoch 00028: val_loss did not improve from 0.01926\n","Epoch 29/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0105 - accuracy: 0.9513 - val_loss: 0.0225 - val_accuracy: 0.9046\n","\n","Epoch 00029: val_loss did not improve from 0.01926\n","Epoch 30/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0088 - accuracy: 0.9675 - val_loss: 0.0262 - val_accuracy: 0.8842\n","\n","Epoch 00030: val_loss did not improve from 0.01926\n","Epoch 31/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0062 - accuracy: 0.9752 - val_loss: 0.0233 - val_accuracy: 0.9021\n","\n","Epoch 00031: val_loss did not improve from 0.01926\n","Epoch 32/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0071 - accuracy: 0.9706 - val_loss: 0.0203 - val_accuracy: 0.9145\n","\n","Epoch 00032: val_loss did not improve from 0.01926\n","Epoch 33/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0083 - accuracy: 0.9649 - val_loss: 0.0242 - val_accuracy: 0.9025\n","\n","Epoch 00033: val_loss did not improve from 0.01926\n","Epoch 34/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0069 - accuracy: 0.9688 - val_loss: 0.0234 - val_accuracy: 0.8942\n","\n","Epoch 00034: val_loss did not improve from 0.01926\n","Epoch 35/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0066 - accuracy: 0.9759 - val_loss: 0.0286 - val_accuracy: 0.8780\n","\n","Epoch 00035: val_loss did not improve from 0.01926\n","\n","Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n","Epoch 36/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0032 - accuracy: 0.9893 - val_loss: 0.0157 - val_accuracy: 0.9386\n","\n","Epoch 00036: val_loss improved from 0.01926 to 0.01565, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_2.h5\n","Epoch 37/100\n","302/302 [==============================] - 3s 10ms/step - loss: 7.4034e-04 - accuracy: 0.9996 - val_loss: 0.0154 - val_accuracy: 0.9394\n","\n","Epoch 00037: val_loss improved from 0.01565 to 0.01542, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_2.h5\n","Epoch 38/100\n","302/302 [==============================] - 3s 10ms/step - loss: 5.2290e-04 - accuracy: 0.9997 - val_loss: 0.0154 - val_accuracy: 0.9398\n","\n","Epoch 00038: val_loss did not improve from 0.01542\n","Epoch 39/100\n","302/302 [==============================] - 3s 10ms/step - loss: 4.2025e-04 - accuracy: 0.9998 - val_loss: 0.0157 - val_accuracy: 0.9386\n","\n","Epoch 00039: val_loss did not improve from 0.01542\n","Epoch 40/100\n","302/302 [==============================] - 3s 10ms/step - loss: 3.7694e-04 - accuracy: 0.9995 - val_loss: 0.0156 - val_accuracy: 0.9398\n","\n","Epoch 00040: val_loss did not improve from 0.01542\n","Epoch 41/100\n","302/302 [==============================] - 3s 10ms/step - loss: 3.3967e-04 - accuracy: 0.9999 - val_loss: 0.0157 - val_accuracy: 0.9411\n","\n","Epoch 00041: val_loss did not improve from 0.01542\n","Epoch 42/100\n","302/302 [==============================] - 3s 10ms/step - loss: 3.0023e-04 - accuracy: 0.9995 - val_loss: 0.0158 - val_accuracy: 0.9427\n","\n","Epoch 00042: val_loss did not improve from 0.01542\n","Epoch 43/100\n","302/302 [==============================] - 3s 10ms/step - loss: 2.5282e-04 - accuracy: 0.9995 - val_loss: 0.0157 - val_accuracy: 0.9423\n","\n","Epoch 00043: val_loss did not improve from 0.01542\n","Epoch 44/100\n","302/302 [==============================] - 3s 10ms/step - loss: 2.1325e-04 - accuracy: 0.9997 - val_loss: 0.0168 - val_accuracy: 0.9373\n","\n","Epoch 00044: val_loss did not improve from 0.01542\n","Epoch 45/100\n","302/302 [==============================] - 3s 10ms/step - loss: 2.3568e-04 - accuracy: 0.9993 - val_loss: 0.0160 - val_accuracy: 0.9432\n","\n","Epoch 00045: val_loss did not improve from 0.01542\n","Epoch 46/100\n","302/302 [==============================] - 3s 10ms/step - loss: 2.0914e-04 - accuracy: 0.9998 - val_loss: 0.0164 - val_accuracy: 0.9427\n","\n","Epoch 00046: val_loss did not improve from 0.01542\n","Epoch 47/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.5944e-04 - accuracy: 0.9995 - val_loss: 0.0166 - val_accuracy: 0.9402\n","\n","Epoch 00047: val_loss did not improve from 0.01542\n","\n","Epoch 00047: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n","Epoch 48/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.0577e-04 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 0.9427\n","\n","Epoch 00048: val_loss did not improve from 0.01542\n","Epoch 49/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.0964e-04 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 0.9427\n","\n","Epoch 00049: val_loss did not improve from 0.01542\n","Epoch 50/100\n","302/302 [==============================] - 3s 10ms/step - loss: 9.8538e-05 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 0.9432\n","\n","Epoch 00050: val_loss did not improve from 0.01542\n","Epoch 51/100\n","302/302 [==============================] - 3s 10ms/step - loss: 9.8330e-05 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9427\n","\n","Epoch 00051: val_loss did not improve from 0.01542\n","Epoch 52/100\n","302/302 [==============================] - 3s 10ms/step - loss: 9.7119e-05 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9423\n","\n","Epoch 00052: val_loss did not improve from 0.01542\n","Epoch 53/100\n","302/302 [==============================] - 3s 10ms/step - loss: 8.8777e-05 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9436\n","\n","Epoch 00053: val_loss did not improve from 0.01542\n","Epoch 54/100\n","302/302 [==============================] - 3s 10ms/step - loss: 8.6070e-05 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9427\n","\n","Epoch 00054: val_loss did not improve from 0.01542\n","Epoch 55/100\n","302/302 [==============================] - 3s 10ms/step - loss: 8.6661e-05 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9432\n","\n","Epoch 00055: val_loss did not improve from 0.01542\n","Epoch 56/100\n","302/302 [==============================] - 3s 10ms/step - loss: 8.4079e-05 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9440\n","\n","Epoch 00056: val_loss did not improve from 0.01542\n","Epoch 57/100\n","302/302 [==============================] - 3s 10ms/step - loss: 7.9039e-05 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9440\n","\n","Epoch 00057: val_loss did not improve from 0.01542\n","\n","Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n","Epoch 00057: early stopping\n","------------------------ Fold 3/5 ------------------------\n","(9640, 100, 12) (2410, 100, 12) (9640, 34) (2410, 34)\n","Epoch 1/100\n","302/302 [==============================] - 6s 11ms/step - loss: 1.4693 - accuracy: 0.0809 - val_loss: 0.1182 - val_accuracy: 0.2129\n","\n","Epoch 00001: val_loss improved from inf to 0.11820, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_3.h5\n","Epoch 2/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.1088 - accuracy: 0.2553 - val_loss: 0.0977 - val_accuracy: 0.3307\n","\n","Epoch 00002: val_loss improved from 0.11820 to 0.09766, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_3.h5\n","Epoch 3/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0896 - accuracy: 0.3699 - val_loss: 0.0820 - val_accuracy: 0.4448\n","\n","Epoch 00003: val_loss improved from 0.09766 to 0.08204, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_3.h5\n","Epoch 4/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0756 - accuracy: 0.4743 - val_loss: 0.0753 - val_accuracy: 0.4751\n","\n","Epoch 00004: val_loss improved from 0.08204 to 0.07526, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_3.h5\n","Epoch 5/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0635 - accuracy: 0.5747 - val_loss: 0.0642 - val_accuracy: 0.6004\n","\n","Epoch 00005: val_loss improved from 0.07526 to 0.06425, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_3.h5\n","Epoch 6/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0535 - accuracy: 0.6467 - val_loss: 0.0601 - val_accuracy: 0.6357\n","\n","Epoch 00006: val_loss improved from 0.06425 to 0.06012, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_3.h5\n","Epoch 7/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0480 - accuracy: 0.6965 - val_loss: 0.0568 - val_accuracy: 0.6290\n","\n","Epoch 00007: val_loss improved from 0.06012 to 0.05680, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_3.h5\n","Epoch 8/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0418 - accuracy: 0.7368 - val_loss: 0.0421 - val_accuracy: 0.7685\n","\n","Epoch 00008: val_loss improved from 0.05680 to 0.04205, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_3.h5\n","Epoch 9/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0359 - accuracy: 0.7772 - val_loss: 0.0420 - val_accuracy: 0.7680\n","\n","Epoch 00009: val_loss improved from 0.04205 to 0.04203, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_3.h5\n","Epoch 10/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0301 - accuracy: 0.8293 - val_loss: 0.0487 - val_accuracy: 0.7282\n","\n","Epoch 00010: val_loss did not improve from 0.04203\n","Epoch 11/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0296 - accuracy: 0.8315 - val_loss: 0.0403 - val_accuracy: 0.7884\n","\n","Epoch 00011: val_loss improved from 0.04203 to 0.04030, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_3.h5\n","Epoch 12/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0266 - accuracy: 0.8592 - val_loss: 0.0406 - val_accuracy: 0.7813\n","\n","Epoch 00012: val_loss did not improve from 0.04030\n","Epoch 13/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0239 - accuracy: 0.8652 - val_loss: 0.0403 - val_accuracy: 0.7809\n","\n","Epoch 00013: val_loss improved from 0.04030 to 0.04029, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_3.h5\n","Epoch 14/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0207 - accuracy: 0.8889 - val_loss: 0.0352 - val_accuracy: 0.8373\n","\n","Epoch 00014: val_loss improved from 0.04029 to 0.03524, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_3.h5\n","Epoch 15/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0176 - accuracy: 0.9107 - val_loss: 0.0328 - val_accuracy: 0.8461\n","\n","Epoch 00015: val_loss improved from 0.03524 to 0.03280, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_3.h5\n","Epoch 16/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0179 - accuracy: 0.9098 - val_loss: 0.0348 - val_accuracy: 0.8253\n","\n","Epoch 00016: val_loss did not improve from 0.03280\n","Epoch 17/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0178 - accuracy: 0.9094 - val_loss: 0.0340 - val_accuracy: 0.8618\n","\n","Epoch 00017: val_loss did not improve from 0.03280\n","Epoch 18/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0173 - accuracy: 0.9113 - val_loss: 0.0308 - val_accuracy: 0.8805\n","\n","Epoch 00018: val_loss improved from 0.03280 to 0.03076, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_3.h5\n","Epoch 19/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0170 - accuracy: 0.9234 - val_loss: 0.0291 - val_accuracy: 0.8855\n","\n","Epoch 00019: val_loss improved from 0.03076 to 0.02914, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_3.h5\n","Epoch 20/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0139 - accuracy: 0.9352 - val_loss: 0.0309 - val_accuracy: 0.8672\n","\n","Epoch 00020: val_loss did not improve from 0.02914\n","Epoch 21/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0112 - accuracy: 0.9446 - val_loss: 0.0245 - val_accuracy: 0.8988\n","\n","Epoch 00021: val_loss improved from 0.02914 to 0.02449, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_3.h5\n","Epoch 22/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0101 - accuracy: 0.9539 - val_loss: 0.0303 - val_accuracy: 0.8722\n","\n","Epoch 00022: val_loss did not improve from 0.02449\n","Epoch 23/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0117 - accuracy: 0.9496 - val_loss: 0.0286 - val_accuracy: 0.8871\n","\n","Epoch 00023: val_loss did not improve from 0.02449\n","Epoch 24/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0160 - accuracy: 0.9288 - val_loss: 0.0470 - val_accuracy: 0.8187\n","\n","Epoch 00024: val_loss did not improve from 0.02449\n","Epoch 25/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0164 - accuracy: 0.9436 - val_loss: 0.0326 - val_accuracy: 0.8664\n","\n","Epoch 00025: val_loss did not improve from 0.02449\n","Epoch 26/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0091 - accuracy: 0.9621 - val_loss: 0.0269 - val_accuracy: 0.9083\n","\n","Epoch 00026: val_loss did not improve from 0.02449\n","Epoch 27/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0096 - accuracy: 0.9572 - val_loss: 0.0279 - val_accuracy: 0.9004\n","\n","Epoch 00027: val_loss did not improve from 0.02449\n","Epoch 28/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0069 - accuracy: 0.9698 - val_loss: 0.0302 - val_accuracy: 0.8975\n","\n","Epoch 00028: val_loss did not improve from 0.02449\n","Epoch 29/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0103 - accuracy: 0.9566 - val_loss: 0.0224 - val_accuracy: 0.9274\n","\n","Epoch 00029: val_loss improved from 0.02449 to 0.02241, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_3.h5\n","Epoch 30/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0049 - accuracy: 0.9790 - val_loss: 0.0314 - val_accuracy: 0.8826\n","\n","Epoch 00030: val_loss did not improve from 0.02241\n","Epoch 31/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0095 - accuracy: 0.9632 - val_loss: 0.0298 - val_accuracy: 0.8730\n","\n","Epoch 00031: val_loss did not improve from 0.02241\n","Epoch 32/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0070 - accuracy: 0.9688 - val_loss: 0.0358 - val_accuracy: 0.8780\n","\n","Epoch 00032: val_loss did not improve from 0.02241\n","Epoch 33/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0092 - accuracy: 0.9604 - val_loss: 0.0228 - val_accuracy: 0.9241\n","\n","Epoch 00033: val_loss did not improve from 0.02241\n","Epoch 34/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0052 - accuracy: 0.9797 - val_loss: 0.0373 - val_accuracy: 0.8938\n","\n","Epoch 00034: val_loss did not improve from 0.02241\n","Epoch 35/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0085 - accuracy: 0.9648 - val_loss: 0.0271 - val_accuracy: 0.9178\n","\n","Epoch 00035: val_loss did not improve from 0.02241\n","Epoch 36/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0062 - accuracy: 0.9783 - val_loss: 0.0333 - val_accuracy: 0.8967\n","\n","Epoch 00036: val_loss did not improve from 0.02241\n","Epoch 37/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0073 - accuracy: 0.9713 - val_loss: 0.0317 - val_accuracy: 0.9008\n","\n","Epoch 00037: val_loss did not improve from 0.02241\n","Epoch 38/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0109 - accuracy: 0.9496 - val_loss: 0.0286 - val_accuracy: 0.9137\n","\n","Epoch 00038: val_loss did not improve from 0.02241\n","Epoch 39/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0046 - accuracy: 0.9839 - val_loss: 0.0285 - val_accuracy: 0.9166\n","\n","Epoch 00039: val_loss did not improve from 0.02241\n","\n","Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n","Epoch 40/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0020 - accuracy: 0.9953 - val_loss: 0.0221 - val_accuracy: 0.9452\n","\n","Epoch 00040: val_loss improved from 0.02241 to 0.02205, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_3.h5\n","Epoch 41/100\n","302/302 [==============================] - 3s 10ms/step - loss: 5.4607e-04 - accuracy: 0.9992 - val_loss: 0.0221 - val_accuracy: 0.9456\n","\n","Epoch 00041: val_loss did not improve from 0.02205\n","Epoch 42/100\n","302/302 [==============================] - 3s 10ms/step - loss: 4.2172e-04 - accuracy: 0.9992 - val_loss: 0.0222 - val_accuracy: 0.9465\n","\n","Epoch 00042: val_loss did not improve from 0.02205\n","Epoch 43/100\n","302/302 [==============================] - 3s 10ms/step - loss: 3.1495e-04 - accuracy: 0.9999 - val_loss: 0.0215 - val_accuracy: 0.9481\n","\n","Epoch 00043: val_loss improved from 0.02205 to 0.02155, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_3.h5\n","Epoch 44/100\n","302/302 [==============================] - 3s 10ms/step - loss: 2.8104e-04 - accuracy: 0.9998 - val_loss: 0.0214 - val_accuracy: 0.9485\n","\n","Epoch 00044: val_loss improved from 0.02155 to 0.02137, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_3.h5\n","Epoch 45/100\n","302/302 [==============================] - 3s 10ms/step - loss: 2.7255e-04 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 0.9502\n","\n","Epoch 00045: val_loss did not improve from 0.02137\n","Epoch 46/100\n","302/302 [==============================] - 3s 10ms/step - loss: 2.0693e-04 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 0.9494\n","\n","Epoch 00046: val_loss did not improve from 0.02137\n","Epoch 47/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.6553e-04 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 0.9515\n","\n","Epoch 00047: val_loss did not improve from 0.02137\n","Epoch 48/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.5471e-04 - accuracy: 1.0000 - val_loss: 0.0220 - val_accuracy: 0.9502\n","\n","Epoch 00048: val_loss did not improve from 0.02137\n","Epoch 49/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.4125e-04 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 0.9510\n","\n","Epoch 00049: val_loss did not improve from 0.02137\n","Epoch 50/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.1897e-04 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 0.9502\n","\n","Epoch 00050: val_loss did not improve from 0.02137\n","Epoch 51/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.0526e-04 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 0.9506\n","\n","Epoch 00051: val_loss did not improve from 0.02137\n","Epoch 52/100\n","302/302 [==============================] - 3s 10ms/step - loss: 9.3314e-05 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 0.9531\n","\n","Epoch 00052: val_loss did not improve from 0.02137\n","Epoch 53/100\n","302/302 [==============================] - 3s 10ms/step - loss: 7.2401e-05 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 0.9535\n","\n","Epoch 00053: val_loss improved from 0.02137 to 0.02137, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_3.h5\n","Epoch 54/100\n","302/302 [==============================] - 3s 10ms/step - loss: 9.1446e-05 - accuracy: 0.9999 - val_loss: 0.0229 - val_accuracy: 0.9502\n","\n","Epoch 00054: val_loss did not improve from 0.02137\n","\n","Epoch 00054: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n","Epoch 55/100\n","302/302 [==============================] - 3s 10ms/step - loss: 6.4367e-05 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 0.9519\n","\n","Epoch 00055: val_loss did not improve from 0.02137\n","Epoch 56/100\n","302/302 [==============================] - 3s 10ms/step - loss: 4.9590e-05 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9523\n","\n","Epoch 00056: val_loss did not improve from 0.02137\n","Epoch 57/100\n","302/302 [==============================] - 3s 10ms/step - loss: 4.8899e-05 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9523\n","\n","Epoch 00057: val_loss did not improve from 0.02137\n","Epoch 58/100\n","302/302 [==============================] - 3s 10ms/step - loss: 4.7468e-05 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 0.9519\n","\n","Epoch 00058: val_loss did not improve from 0.02137\n","Epoch 59/100\n","302/302 [==============================] - 3s 10ms/step - loss: 4.4360e-05 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 0.9527\n","\n","Epoch 00059: val_loss did not improve from 0.02137\n","Epoch 60/100\n","302/302 [==============================] - 3s 10ms/step - loss: 4.1672e-05 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 0.9523\n","\n","Epoch 00060: val_loss did not improve from 0.02137\n","Epoch 61/100\n","302/302 [==============================] - 3s 10ms/step - loss: 4.3372e-05 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 0.9523\n","\n","Epoch 00061: val_loss did not improve from 0.02137\n","Epoch 62/100\n","302/302 [==============================] - 3s 10ms/step - loss: 4.2104e-05 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 0.9523\n","\n","Epoch 00062: val_loss did not improve from 0.02137\n","Epoch 63/100\n","302/302 [==============================] - 3s 10ms/step - loss: 4.0826e-05 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9523\n","\n","Epoch 00063: val_loss did not improve from 0.02137\n","Epoch 64/100\n","302/302 [==============================] - 3s 10ms/step - loss: 3.8178e-05 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 0.9535\n","\n","Epoch 00064: val_loss did not improve from 0.02137\n","\n","Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n","Epoch 65/100\n","302/302 [==============================] - 3s 10ms/step - loss: 3.6076e-05 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 0.9535\n","\n","Epoch 00065: val_loss did not improve from 0.02137\n","Epoch 66/100\n","302/302 [==============================] - 3s 10ms/step - loss: 3.8551e-05 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9535\n","\n","Epoch 00066: val_loss did not improve from 0.02137\n","Epoch 67/100\n","302/302 [==============================] - 3s 10ms/step - loss: 3.6096e-05 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9531\n","\n","Epoch 00067: val_loss did not improve from 0.02137\n","Epoch 68/100\n","302/302 [==============================] - 3s 10ms/step - loss: 3.8072e-05 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9531\n","\n","Epoch 00068: val_loss did not improve from 0.02137\n","Epoch 69/100\n","302/302 [==============================] - 3s 10ms/step - loss: 3.6594e-05 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9531\n","\n","Epoch 00069: val_loss did not improve from 0.02137\n","Epoch 70/100\n","302/302 [==============================] - 3s 10ms/step - loss: 3.6030e-05 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9531\n","\n","Epoch 00070: val_loss did not improve from 0.02137\n","Epoch 71/100\n","302/302 [==============================] - 3s 10ms/step - loss: 3.5568e-05 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9531\n","\n","Epoch 00071: val_loss did not improve from 0.02137\n","Epoch 72/100\n","302/302 [==============================] - 3s 10ms/step - loss: 3.8489e-05 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9531\n","\n","Epoch 00072: val_loss did not improve from 0.02137\n","Epoch 73/100\n","302/302 [==============================] - 3s 10ms/step - loss: 3.4687e-05 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 0.9531\n","\n","Epoch 00073: val_loss did not improve from 0.02137\n","Epoch 00073: early stopping\n","------------------------ Fold 4/5 ------------------------\n","(9640, 100, 12) (2410, 100, 12) (9640, 34) (2410, 34)\n","Epoch 1/100\n","302/302 [==============================] - 5s 12ms/step - loss: 1.1161 - accuracy: 0.0770 - val_loss: 0.1185 - val_accuracy: 0.2257\n","\n","Epoch 00001: val_loss improved from inf to 0.11854, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_4.h5\n","Epoch 2/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.1083 - accuracy: 0.2538 - val_loss: 0.0903 - val_accuracy: 0.3556\n","\n","Epoch 00002: val_loss improved from 0.11854 to 0.09034, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_4.h5\n","Epoch 3/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0912 - accuracy: 0.3567 - val_loss: 0.0792 - val_accuracy: 0.4419\n","\n","Epoch 00003: val_loss improved from 0.09034 to 0.07916, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_4.h5\n","Epoch 4/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0748 - accuracy: 0.4581 - val_loss: 0.0668 - val_accuracy: 0.5278\n","\n","Epoch 00004: val_loss improved from 0.07916 to 0.06684, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_4.h5\n","Epoch 5/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0627 - accuracy: 0.5658 - val_loss: 0.0582 - val_accuracy: 0.5855\n","\n","Epoch 00005: val_loss improved from 0.06684 to 0.05818, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_4.h5\n","Epoch 6/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0542 - accuracy: 0.6303 - val_loss: 0.0482 - val_accuracy: 0.6822\n","\n","Epoch 00006: val_loss improved from 0.05818 to 0.04822, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_4.h5\n","Epoch 7/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0450 - accuracy: 0.7114 - val_loss: 0.0393 - val_accuracy: 0.7664\n","\n","Epoch 00007: val_loss improved from 0.04822 to 0.03928, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_4.h5\n","Epoch 8/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0398 - accuracy: 0.7580 - val_loss: 0.0366 - val_accuracy: 0.7726\n","\n","Epoch 00008: val_loss improved from 0.03928 to 0.03656, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_4.h5\n","Epoch 9/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0345 - accuracy: 0.7893 - val_loss: 0.0312 - val_accuracy: 0.8137\n","\n","Epoch 00009: val_loss improved from 0.03656 to 0.03116, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_4.h5\n","Epoch 10/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0282 - accuracy: 0.8387 - val_loss: 0.0249 - val_accuracy: 0.8589\n","\n","Epoch 00010: val_loss improved from 0.03116 to 0.02493, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_4.h5\n","Epoch 11/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0252 - accuracy: 0.8615 - val_loss: 0.0266 - val_accuracy: 0.8394\n","\n","Epoch 00011: val_loss did not improve from 0.02493\n","Epoch 12/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0226 - accuracy: 0.8774 - val_loss: 0.0303 - val_accuracy: 0.8166\n","\n","Epoch 00012: val_loss did not improve from 0.02493\n","Epoch 13/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0219 - accuracy: 0.8811 - val_loss: 0.0269 - val_accuracy: 0.8469\n","\n","Epoch 00013: val_loss did not improve from 0.02493\n","Epoch 14/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0195 - accuracy: 0.9030 - val_loss: 0.0176 - val_accuracy: 0.9149\n","\n","Epoch 00014: val_loss improved from 0.02493 to 0.01761, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_4.h5\n","Epoch 15/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0170 - accuracy: 0.9159 - val_loss: 0.0263 - val_accuracy: 0.8456\n","\n","Epoch 00015: val_loss did not improve from 0.01761\n","Epoch 16/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0160 - accuracy: 0.9175 - val_loss: 0.0188 - val_accuracy: 0.9058\n","\n","Epoch 00016: val_loss did not improve from 0.01761\n","Epoch 17/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0163 - accuracy: 0.9247 - val_loss: 0.0189 - val_accuracy: 0.9079\n","\n","Epoch 00017: val_loss did not improve from 0.01761\n","Epoch 18/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0137 - accuracy: 0.9325 - val_loss: 0.0216 - val_accuracy: 0.8838\n","\n","Epoch 00018: val_loss did not improve from 0.01761\n","Epoch 19/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0128 - accuracy: 0.9380 - val_loss: 0.0168 - val_accuracy: 0.9270\n","\n","Epoch 00019: val_loss improved from 0.01761 to 0.01681, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_4.h5\n","Epoch 20/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0118 - accuracy: 0.9432 - val_loss: 0.0211 - val_accuracy: 0.9004\n","\n","Epoch 00020: val_loss did not improve from 0.01681\n","Epoch 21/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0117 - accuracy: 0.9489 - val_loss: 0.0166 - val_accuracy: 0.9149\n","\n","Epoch 00021: val_loss improved from 0.01681 to 0.01657, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_4.h5\n","Epoch 22/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0113 - accuracy: 0.9488 - val_loss: 0.0202 - val_accuracy: 0.8925\n","\n","Epoch 00022: val_loss did not improve from 0.01657\n","Epoch 23/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0099 - accuracy: 0.9518 - val_loss: 0.0162 - val_accuracy: 0.9187\n","\n","Epoch 00023: val_loss improved from 0.01657 to 0.01624, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_4.h5\n","Epoch 24/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0143 - accuracy: 0.9374 - val_loss: 0.0193 - val_accuracy: 0.8979\n","\n","Epoch 00024: val_loss did not improve from 0.01624\n","Epoch 25/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0099 - accuracy: 0.9580 - val_loss: 0.0189 - val_accuracy: 0.9083\n","\n","Epoch 00025: val_loss did not improve from 0.01624\n","Epoch 26/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0144 - accuracy: 0.9431 - val_loss: 0.0161 - val_accuracy: 0.9320\n","\n","Epoch 00026: val_loss improved from 0.01624 to 0.01609, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_4.h5\n","Epoch 27/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0065 - accuracy: 0.9728 - val_loss: 0.0122 - val_accuracy: 0.9506\n","\n","Epoch 00027: val_loss improved from 0.01609 to 0.01219, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_4.h5\n","Epoch 28/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0075 - accuracy: 0.9665 - val_loss: 0.0124 - val_accuracy: 0.9477\n","\n","Epoch 00028: val_loss did not improve from 0.01219\n","Epoch 29/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0067 - accuracy: 0.9719 - val_loss: 0.0107 - val_accuracy: 0.9593\n","\n","Epoch 00029: val_loss improved from 0.01219 to 0.01065, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_4.h5\n","Epoch 30/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0077 - accuracy: 0.9683 - val_loss: 0.0122 - val_accuracy: 0.9498\n","\n","Epoch 00030: val_loss did not improve from 0.01065\n","Epoch 31/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0075 - accuracy: 0.9723 - val_loss: 0.0122 - val_accuracy: 0.9510\n","\n","Epoch 00031: val_loss did not improve from 0.01065\n","Epoch 32/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0081 - accuracy: 0.9678 - val_loss: 0.0124 - val_accuracy: 0.9506\n","\n","Epoch 00032: val_loss did not improve from 0.01065\n","Epoch 33/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0070 - accuracy: 0.9708 - val_loss: 0.0170 - val_accuracy: 0.9249\n","\n","Epoch 00033: val_loss did not improve from 0.01065\n","Epoch 34/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0052 - accuracy: 0.9800 - val_loss: 0.0130 - val_accuracy: 0.9515\n","\n","Epoch 00034: val_loss did not improve from 0.01065\n","Epoch 35/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0087 - accuracy: 0.9609 - val_loss: 0.0098 - val_accuracy: 0.9614\n","\n","Epoch 00035: val_loss improved from 0.01065 to 0.00984, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_4.h5\n","Epoch 36/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0049 - accuracy: 0.9803 - val_loss: 0.0254 - val_accuracy: 0.8801\n","\n","Epoch 00036: val_loss did not improve from 0.00984\n","Epoch 37/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0080 - accuracy: 0.9711 - val_loss: 0.0137 - val_accuracy: 0.9378\n","\n","Epoch 00037: val_loss did not improve from 0.00984\n","Epoch 38/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0079 - accuracy: 0.9678 - val_loss: 0.0101 - val_accuracy: 0.9610\n","\n","Epoch 00038: val_loss did not improve from 0.00984\n","Epoch 39/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0053 - accuracy: 0.9805 - val_loss: 0.0133 - val_accuracy: 0.9448\n","\n","Epoch 00039: val_loss did not improve from 0.00984\n","Epoch 40/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0036 - accuracy: 0.9850 - val_loss: 0.0267 - val_accuracy: 0.9390\n","\n","Epoch 00040: val_loss did not improve from 0.00984\n","Epoch 41/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0093 - accuracy: 0.9684 - val_loss: 0.0136 - val_accuracy: 0.9465\n","\n","Epoch 00041: val_loss did not improve from 0.00984\n","Epoch 42/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0065 - accuracy: 0.9728 - val_loss: 0.0094 - val_accuracy: 0.9668\n","\n","Epoch 00042: val_loss improved from 0.00984 to 0.00936, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_4.h5\n","Epoch 43/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0032 - accuracy: 0.9889 - val_loss: 0.0115 - val_accuracy: 0.9473\n","\n","Epoch 00043: val_loss did not improve from 0.00936\n","Epoch 44/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0047 - accuracy: 0.9834 - val_loss: 0.0113 - val_accuracy: 0.9585\n","\n","Epoch 00044: val_loss did not improve from 0.00936\n","Epoch 45/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0055 - accuracy: 0.9771 - val_loss: 0.0166 - val_accuracy: 0.9357\n","\n","Epoch 00045: val_loss did not improve from 0.00936\n","Epoch 46/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0047 - accuracy: 0.9817 - val_loss: 0.0115 - val_accuracy: 0.9593\n","\n","Epoch 00046: val_loss did not improve from 0.00936\n","Epoch 47/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0026 - accuracy: 0.9924 - val_loss: 0.0149 - val_accuracy: 0.9398\n","\n","Epoch 00047: val_loss did not improve from 0.00936\n","Epoch 48/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0067 - accuracy: 0.9724 - val_loss: 0.0165 - val_accuracy: 0.9436\n","\n","Epoch 00048: val_loss did not improve from 0.00936\n","Epoch 49/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0042 - accuracy: 0.9899 - val_loss: 0.0210 - val_accuracy: 0.9390\n","\n","Epoch 00049: val_loss did not improve from 0.00936\n","Epoch 50/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0048 - accuracy: 0.9813 - val_loss: 0.0112 - val_accuracy: 0.9660\n","\n","Epoch 00050: val_loss did not improve from 0.00936\n","Epoch 51/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0036 - accuracy: 0.9861 - val_loss: 0.0096 - val_accuracy: 0.9622\n","\n","Epoch 00051: val_loss did not improve from 0.00936\n","Epoch 52/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0025 - accuracy: 0.9900 - val_loss: 0.0093 - val_accuracy: 0.9614\n","\n","Epoch 00052: val_loss improved from 0.00936 to 0.00926, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_4.h5\n","\n","Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n","Epoch 53/100\n","302/302 [==============================] - 3s 10ms/step - loss: 9.4835e-04 - accuracy: 0.9963 - val_loss: 0.0063 - val_accuracy: 0.9768\n","\n","Epoch 00053: val_loss improved from 0.00926 to 0.00630, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_4.h5\n","Epoch 54/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.8332e-04 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9772\n","\n","Epoch 00054: val_loss did not improve from 0.00630\n","Epoch 55/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.3439e-04 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9776\n","\n","Epoch 00055: val_loss did not improve from 0.00630\n","Epoch 56/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.2711e-04 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9776\n","\n","Epoch 00056: val_loss improved from 0.00630 to 0.00626, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_4.h5\n","Epoch 57/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.1695e-04 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9772\n","\n","Epoch 00057: val_loss did not improve from 0.00626\n","Epoch 58/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.0204e-04 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9788\n","\n","Epoch 00058: val_loss did not improve from 0.00626\n","Epoch 59/100\n","302/302 [==============================] - 3s 10ms/step - loss: 7.6044e-05 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9780\n","\n","Epoch 00059: val_loss did not improve from 0.00626\n","Epoch 60/100\n","302/302 [==============================] - 3s 10ms/step - loss: 9.2753e-05 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9788\n","\n","Epoch 00060: val_loss did not improve from 0.00626\n","Epoch 61/100\n","302/302 [==============================] - 3s 10ms/step - loss: 6.5114e-05 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9788\n","\n","Epoch 00061: val_loss did not improve from 0.00626\n","Epoch 62/100\n","302/302 [==============================] - 3s 10ms/step - loss: 5.5923e-05 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9780\n","\n","Epoch 00062: val_loss did not improve from 0.00626\n","Epoch 63/100\n","302/302 [==============================] - 3s 10ms/step - loss: 4.0902e-05 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9793\n","\n","Epoch 00063: val_loss did not improve from 0.00626\n","\n","Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n","Epoch 64/100\n","302/302 [==============================] - 3s 10ms/step - loss: 8.1527e-05 - accuracy: 0.9997 - val_loss: 0.0065 - val_accuracy: 0.9797\n","\n","Epoch 00064: val_loss did not improve from 0.00626\n","Epoch 65/100\n","302/302 [==============================] - 3s 10ms/step - loss: 4.6083e-05 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9788\n","\n","Epoch 00065: val_loss did not improve from 0.00626\n","Epoch 66/100\n","302/302 [==============================] - 3s 10ms/step - loss: 4.3474e-05 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9788\n","\n","Epoch 00066: val_loss did not improve from 0.00626\n","Epoch 67/100\n","302/302 [==============================] - 3s 10ms/step - loss: 3.8448e-05 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9793\n","\n","Epoch 00067: val_loss did not improve from 0.00626\n","Epoch 68/100\n","302/302 [==============================] - 3s 10ms/step - loss: 3.5968e-05 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9793\n","\n","Epoch 00068: val_loss did not improve from 0.00626\n","Epoch 69/100\n","302/302 [==============================] - 3s 10ms/step - loss: 3.4416e-05 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9793\n","\n","Epoch 00069: val_loss did not improve from 0.00626\n","Epoch 70/100\n","302/302 [==============================] - 3s 11ms/step - loss: 3.5170e-05 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9788\n","\n","Epoch 00070: val_loss did not improve from 0.00626\n","Epoch 71/100\n","302/302 [==============================] - 3s 11ms/step - loss: 3.8337e-05 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9797\n","\n","Epoch 00071: val_loss did not improve from 0.00626\n","Epoch 72/100\n","302/302 [==============================] - 3s 10ms/step - loss: 3.4205e-05 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9797\n","\n","Epoch 00072: val_loss did not improve from 0.00626\n","Epoch 73/100\n","302/302 [==============================] - 3s 10ms/step - loss: 3.3955e-05 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9793\n","\n","Epoch 00073: val_loss did not improve from 0.00626\n","\n","Epoch 00073: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n","Epoch 74/100\n","302/302 [==============================] - 3s 10ms/step - loss: 3.0110e-05 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9797\n","\n","Epoch 00074: val_loss did not improve from 0.00626\n","Epoch 75/100\n","302/302 [==============================] - 3s 10ms/step - loss: 3.2201e-05 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9797\n","\n","Epoch 00075: val_loss did not improve from 0.00626\n","Epoch 76/100\n","302/302 [==============================] - 3s 10ms/step - loss: 3.1716e-05 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9797\n","\n","Epoch 00076: val_loss did not improve from 0.00626\n","Epoch 00076: early stopping\n","------------------------ Fold 5/5 ------------------------\n","(9640, 100, 12) (2410, 100, 12) (9640, 34) (2410, 34)\n","Epoch 1/100\n","302/302 [==============================] - 5s 12ms/step - loss: 1.7596 - accuracy: 0.0698 - val_loss: 0.1197 - val_accuracy: 0.2000\n","\n","Epoch 00001: val_loss improved from inf to 0.11967, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_5.h5\n","Epoch 2/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.1184 - accuracy: 0.2216 - val_loss: 0.1029 - val_accuracy: 0.2701\n","\n","Epoch 00002: val_loss improved from 0.11967 to 0.10287, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_5.h5\n","Epoch 3/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0955 - accuracy: 0.3272 - val_loss: 0.0911 - val_accuracy: 0.3602\n","\n","Epoch 00003: val_loss improved from 0.10287 to 0.09112, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_5.h5\n","Epoch 4/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0836 - accuracy: 0.4085 - val_loss: 0.0836 - val_accuracy: 0.4174\n","\n","Epoch 00004: val_loss improved from 0.09112 to 0.08365, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_5.h5\n","Epoch 5/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0742 - accuracy: 0.4782 - val_loss: 0.0700 - val_accuracy: 0.5112\n","\n","Epoch 00005: val_loss improved from 0.08365 to 0.07003, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_5.h5\n","Epoch 6/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0641 - accuracy: 0.5461 - val_loss: 0.0677 - val_accuracy: 0.5195\n","\n","Epoch 00006: val_loss improved from 0.07003 to 0.06768, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_5.h5\n","Epoch 7/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0571 - accuracy: 0.5980 - val_loss: 0.0607 - val_accuracy: 0.6091\n","\n","Epoch 00007: val_loss improved from 0.06768 to 0.06066, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_5.h5\n","Epoch 8/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0510 - accuracy: 0.6507 - val_loss: 0.0533 - val_accuracy: 0.6498\n","\n","Epoch 00008: val_loss improved from 0.06066 to 0.05329, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_5.h5\n","Epoch 9/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0453 - accuracy: 0.7034 - val_loss: 0.0507 - val_accuracy: 0.6867\n","\n","Epoch 00009: val_loss improved from 0.05329 to 0.05070, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_5.h5\n","Epoch 10/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0411 - accuracy: 0.7365 - val_loss: 0.0453 - val_accuracy: 0.7290\n","\n","Epoch 00010: val_loss improved from 0.05070 to 0.04533, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_5.h5\n","Epoch 11/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0348 - accuracy: 0.7893 - val_loss: 0.0479 - val_accuracy: 0.7046\n","\n","Epoch 00011: val_loss did not improve from 0.04533\n","Epoch 12/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0334 - accuracy: 0.7977 - val_loss: 0.0439 - val_accuracy: 0.7320\n","\n","Epoch 00012: val_loss improved from 0.04533 to 0.04393, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_5.h5\n","Epoch 13/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0306 - accuracy: 0.8141 - val_loss: 0.0366 - val_accuracy: 0.7871\n","\n","Epoch 00013: val_loss improved from 0.04393 to 0.03656, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_5.h5\n","Epoch 14/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0242 - accuracy: 0.8692 - val_loss: 0.0413 - val_accuracy: 0.7826\n","\n","Epoch 00014: val_loss did not improve from 0.03656\n","Epoch 15/100\n","302/302 [==============================] - 3s 11ms/step - loss: 0.0246 - accuracy: 0.8639 - val_loss: 0.0410 - val_accuracy: 0.7975\n","\n","Epoch 00015: val_loss did not improve from 0.03656\n","Epoch 16/100\n","302/302 [==============================] - 3s 11ms/step - loss: 0.0237 - accuracy: 0.8703 - val_loss: 0.0370 - val_accuracy: 0.8141\n","\n","Epoch 00016: val_loss did not improve from 0.03656\n","Epoch 17/100\n","302/302 [==============================] - 3s 11ms/step - loss: 0.0210 - accuracy: 0.8939 - val_loss: 0.0382 - val_accuracy: 0.8237\n","\n","Epoch 00017: val_loss did not improve from 0.03656\n","Epoch 18/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0177 - accuracy: 0.9085 - val_loss: 0.0350 - val_accuracy: 0.8274\n","\n","Epoch 00018: val_loss improved from 0.03656 to 0.03501, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_5.h5\n","Epoch 19/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0176 - accuracy: 0.9133 - val_loss: 0.0347 - val_accuracy: 0.8573\n","\n","Epoch 00019: val_loss improved from 0.03501 to 0.03465, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_5.h5\n","Epoch 20/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0210 - accuracy: 0.8996 - val_loss: 0.0306 - val_accuracy: 0.8519\n","\n","Epoch 00020: val_loss improved from 0.03465 to 0.03058, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_5.h5\n","Epoch 21/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0137 - accuracy: 0.9360 - val_loss: 0.0298 - val_accuracy: 0.8656\n","\n","Epoch 00021: val_loss improved from 0.03058 to 0.02977, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_5.h5\n","Epoch 22/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0127 - accuracy: 0.9424 - val_loss: 0.0269 - val_accuracy: 0.8710\n","\n","Epoch 00022: val_loss improved from 0.02977 to 0.02687, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_5.h5\n","Epoch 23/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0124 - accuracy: 0.9420 - val_loss: 0.0375 - val_accuracy: 0.8581\n","\n","Epoch 00023: val_loss did not improve from 0.02687\n","Epoch 24/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0116 - accuracy: 0.9511 - val_loss: 0.0319 - val_accuracy: 0.8680\n","\n","Epoch 00024: val_loss did not improve from 0.02687\n","Epoch 25/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0122 - accuracy: 0.9462 - val_loss: 0.0269 - val_accuracy: 0.8739\n","\n","Epoch 00025: val_loss improved from 0.02687 to 0.02687, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_5.h5\n","Epoch 26/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0104 - accuracy: 0.9495 - val_loss: 0.0247 - val_accuracy: 0.9062\n","\n","Epoch 00026: val_loss improved from 0.02687 to 0.02470, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_5.h5\n","Epoch 27/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0116 - accuracy: 0.9535 - val_loss: 0.0280 - val_accuracy: 0.8950\n","\n","Epoch 00027: val_loss did not improve from 0.02470\n","Epoch 28/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0157 - accuracy: 0.9348 - val_loss: 0.0245 - val_accuracy: 0.8963\n","\n","Epoch 00028: val_loss improved from 0.02470 to 0.02450, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_5.h5\n","Epoch 29/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0086 - accuracy: 0.9674 - val_loss: 0.0256 - val_accuracy: 0.9037\n","\n","Epoch 00029: val_loss did not improve from 0.02450\n","Epoch 30/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0083 - accuracy: 0.9646 - val_loss: 0.0245 - val_accuracy: 0.9050\n","\n","Epoch 00030: val_loss did not improve from 0.02450\n","Epoch 31/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0070 - accuracy: 0.9726 - val_loss: 0.0269 - val_accuracy: 0.8938\n","\n","Epoch 00031: val_loss did not improve from 0.02450\n","Epoch 32/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0083 - accuracy: 0.9660 - val_loss: 0.0298 - val_accuracy: 0.8867\n","\n","Epoch 00032: val_loss did not improve from 0.02450\n","Epoch 33/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0083 - accuracy: 0.9641 - val_loss: 0.0230 - val_accuracy: 0.9029\n","\n","Epoch 00033: val_loss improved from 0.02450 to 0.02296, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_5.h5\n","Epoch 34/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0064 - accuracy: 0.9745 - val_loss: 0.0286 - val_accuracy: 0.8801\n","\n","Epoch 00034: val_loss did not improve from 0.02296\n","Epoch 35/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0057 - accuracy: 0.9769 - val_loss: 0.0290 - val_accuracy: 0.8892\n","\n","Epoch 00035: val_loss did not improve from 0.02296\n","Epoch 36/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0077 - accuracy: 0.9691 - val_loss: 0.0448 - val_accuracy: 0.8369\n","\n","Epoch 00036: val_loss did not improve from 0.02296\n","Epoch 37/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0095 - accuracy: 0.9635 - val_loss: 0.0452 - val_accuracy: 0.8639\n","\n","Epoch 00037: val_loss did not improve from 0.02296\n","Epoch 38/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0174 - accuracy: 0.9435 - val_loss: 0.0234 - val_accuracy: 0.9083\n","\n","Epoch 00038: val_loss did not improve from 0.02296\n","Epoch 39/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0055 - accuracy: 0.9807 - val_loss: 0.0240 - val_accuracy: 0.9050\n","\n","Epoch 00039: val_loss did not improve from 0.02296\n","Epoch 40/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0049 - accuracy: 0.9772 - val_loss: 0.0219 - val_accuracy: 0.9187\n","\n","Epoch 00040: val_loss improved from 0.02296 to 0.02195, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_5.h5\n","Epoch 41/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0065 - accuracy: 0.9710 - val_loss: 0.0195 - val_accuracy: 0.9224\n","\n","Epoch 00041: val_loss improved from 0.02195 to 0.01954, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_5.h5\n","Epoch 42/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0040 - accuracy: 0.9862 - val_loss: 0.0291 - val_accuracy: 0.8909\n","\n","Epoch 00042: val_loss did not improve from 0.01954\n","Epoch 43/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0044 - accuracy: 0.9814 - val_loss: 0.0302 - val_accuracy: 0.8896\n","\n","Epoch 00043: val_loss did not improve from 0.01954\n","Epoch 44/100\n","302/302 [==============================] - 3s 11ms/step - loss: 0.0055 - accuracy: 0.9804 - val_loss: 0.0224 - val_accuracy: 0.9212\n","\n","Epoch 00044: val_loss did not improve from 0.01954\n","Epoch 45/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0033 - accuracy: 0.9890 - val_loss: 0.0255 - val_accuracy: 0.9004\n","\n","Epoch 00045: val_loss did not improve from 0.01954\n","Epoch 46/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0088 - accuracy: 0.9651 - val_loss: 0.0226 - val_accuracy: 0.9133\n","\n","Epoch 00046: val_loss did not improve from 0.01954\n","Epoch 47/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0032 - accuracy: 0.9869 - val_loss: 0.0293 - val_accuracy: 0.8900\n","\n","Epoch 00047: val_loss did not improve from 0.01954\n","Epoch 48/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0055 - accuracy: 0.9775 - val_loss: 0.0295 - val_accuracy: 0.8975\n","\n","Epoch 00048: val_loss did not improve from 0.01954\n","Epoch 49/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0062 - accuracy: 0.9787 - val_loss: 0.0272 - val_accuracy: 0.9212\n","\n","Epoch 00049: val_loss did not improve from 0.01954\n","Epoch 50/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0071 - accuracy: 0.9754 - val_loss: 0.0331 - val_accuracy: 0.8834\n","\n","Epoch 00050: val_loss did not improve from 0.01954\n","Epoch 51/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0078 - accuracy: 0.9741 - val_loss: 0.0254 - val_accuracy: 0.9124\n","\n","Epoch 00051: val_loss did not improve from 0.01954\n","\n","Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n","Epoch 52/100\n","302/302 [==============================] - 3s 10ms/step - loss: 0.0018 - accuracy: 0.9979 - val_loss: 0.0172 - val_accuracy: 0.9411\n","\n","Epoch 00052: val_loss improved from 0.01954 to 0.01723, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_5.h5\n","Epoch 53/100\n","302/302 [==============================] - 3s 10ms/step - loss: 4.8256e-04 - accuracy: 0.9998 - val_loss: 0.0166 - val_accuracy: 0.9465\n","\n","Epoch 00053: val_loss improved from 0.01723 to 0.01663, saving model to Final Experiments/checkpoint/null_class/tcn_separate_classes_sub_s7_fold_5.h5\n","Epoch 54/100\n","302/302 [==============================] - 3s 10ms/step - loss: 3.4791e-04 - accuracy: 0.9999 - val_loss: 0.0167 - val_accuracy: 0.9469\n","\n","Epoch 00054: val_loss did not improve from 0.01663\n","Epoch 55/100\n","302/302 [==============================] - 3s 10ms/step - loss: 2.7826e-04 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9469\n","\n","Epoch 00055: val_loss did not improve from 0.01663\n","Epoch 56/100\n","302/302 [==============================] - 3s 10ms/step - loss: 2.4209e-04 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9461\n","\n","Epoch 00056: val_loss did not improve from 0.01663\n","Epoch 57/100\n","302/302 [==============================] - 3s 10ms/step - loss: 2.1063e-04 - accuracy: 0.9997 - val_loss: 0.0167 - val_accuracy: 0.9502\n","\n","Epoch 00057: val_loss did not improve from 0.01663\n","Epoch 58/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.8243e-04 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9498\n","\n","Epoch 00058: val_loss did not improve from 0.01663\n","Epoch 59/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.4403e-04 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 0.9494\n","\n","Epoch 00059: val_loss did not improve from 0.01663\n","Epoch 60/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.4065e-04 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9506\n","\n","Epoch 00060: val_loss did not improve from 0.01663\n","Epoch 61/100\n","302/302 [==============================] - 3s 10ms/step - loss: 1.1651e-04 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 0.9515\n","\n","Epoch 00061: val_loss did not improve from 0.01663\n","Epoch 62/100\n","302/302 [==============================] - 3s 11ms/step - loss: 1.0260e-04 - accuracy: 0.9999 - val_loss: 0.0171 - val_accuracy: 0.9498\n","\n","Epoch 00062: val_loss did not improve from 0.01663\n","Epoch 63/100\n","302/302 [==============================] - 3s 10ms/step - loss: 8.3022e-05 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 0.9531\n","\n","Epoch 00063: val_loss did not improve from 0.01663\n","\n","Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n","Epoch 64/100\n","302/302 [==============================] - 3s 10ms/step - loss: 6.5149e-05 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 0.9531\n","\n","Epoch 00064: val_loss did not improve from 0.01663\n","Epoch 65/100\n","302/302 [==============================] - 3s 10ms/step - loss: 6.0195e-05 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 0.9539\n","\n","Epoch 00065: val_loss did not improve from 0.01663\n","Epoch 66/100\n","302/302 [==============================] - 3s 10ms/step - loss: 5.7670e-05 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 0.9531\n","\n","Epoch 00066: val_loss did not improve from 0.01663\n","Epoch 67/100\n","302/302 [==============================] - 3s 10ms/step - loss: 6.0399e-05 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 0.9527\n","\n","Epoch 00067: val_loss did not improve from 0.01663\n","Epoch 68/100\n","302/302 [==============================] - 3s 10ms/step - loss: 5.8499e-05 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 0.9527\n","\n","Epoch 00068: val_loss did not improve from 0.01663\n","Epoch 69/100\n","302/302 [==============================] - 3s 10ms/step - loss: 6.0302e-05 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 0.9539\n","\n","Epoch 00069: val_loss did not improve from 0.01663\n","Epoch 70/100\n","302/302 [==============================] - 3s 10ms/step - loss: 5.3232e-05 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 0.9531\n","\n","Epoch 00070: val_loss did not improve from 0.01663\n","Epoch 71/100\n","302/302 [==============================] - 3s 10ms/step - loss: 5.3408e-05 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 0.9531\n","\n","Epoch 00071: val_loss did not improve from 0.01663\n","Epoch 72/100\n","302/302 [==============================] - 3s 11ms/step - loss: 5.0183e-05 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 0.9535\n","\n","Epoch 00072: val_loss did not improve from 0.01663\n","Epoch 73/100\n","302/302 [==============================] - 3s 10ms/step - loss: 5.2593e-05 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 0.9531\n","\n","Epoch 00073: val_loss did not improve from 0.01663\n","\n","Epoch 00073: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n","Epoch 00073: early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yo_WgYOErLA8","executionInfo":{"status":"ok","timestamp":1619989774926,"user_tz":-330,"elapsed":9589,"user":{"displayName":"Sejal Bhalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd83T8nE5o6zGLINWWUfr_S_8fE_h_SM_LXr0WGQ=s64","userId":"12680971253671894594"}},"outputId":"e5b15f67-d31d-4642-fc61-f2854dec54d5"},"source":["average_acc = 0\n","for fold in range(5):\n","    print('------------------------ Fold {}/5'.format(fold+1)+' ------------------------')\n","    X_train, y_train, X_test, y_test, ohe = split(train_inds, test_inds, train_inds_new, test_inds_new, fold, binary=False)\n","    print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n","    n_classes = 34\n","\n","    batch_size = 32\n","    input_shape = (100, 12)\n","\n","    model = build_model(input_shape, n_classes)\n","\n","    labels = ohe.categories_[0]\n","    model_name = 'tcn_separate_classes_sub_{}_fold_{}'.format(sub, fold+1)\n","    model.load_weights('Final Experiments/checkpoint/null_class/{}.h5'.format(model_name))\n","    print('Model loaded succesfully!')\n","    y_pred = model.predict(X_test)\n","    report = classification_report(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), target_names = labels, output_dict=True)\n","    average_acc += report['accuracy']\n","    print(report)\n","print('5-fold Cross Validation Accuracy:', average_acc/5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["------------------------ Fold 1/5 ------------------------\n","(9640, 100, 12) (2410, 100, 12) (9640, 34) (2410, 34)\n","Model loaded succesfully!\n","{'1': {'precision': 0.9859154929577465, 'recall': 1.0, 'f1-score': 0.9929078014184397, 'support': 70}, '10': {'precision': 0.9558823529411765, 'recall': 0.9285714285714286, 'f1-score': 0.9420289855072465, 'support': 70}, '11': {'precision': 0.9722222222222222, 'recall': 1.0, 'f1-score': 0.9859154929577464, 'support': 70}, '12': {'precision': 0.9722222222222222, 'recall': 1.0, 'f1-score': 0.9859154929577464, 'support': 70}, '13': {'precision': 0.9714285714285714, 'recall': 0.9714285714285714, 'f1-score': 0.9714285714285714, 'support': 70}, '14': {'precision': 0.9846153846153847, 'recall': 0.9142857142857143, 'f1-score': 0.9481481481481482, 'support': 70}, '15': {'precision': 0.9672131147540983, 'recall': 0.8428571428571429, 'f1-score': 0.9007633587786259, 'support': 70}, '16': {'precision': 0.9722222222222222, 'recall': 1.0, 'f1-score': 0.9859154929577464, 'support': 70}, '17': {'precision': 0.9305555555555556, 'recall': 0.9571428571428572, 'f1-score': 0.943661971830986, 'support': 70}, '18': {'precision': 0.92, 'recall': 0.9857142857142858, 'f1-score': 0.9517241379310346, 'support': 70}, '20': {'precision': 1.0, 'recall': 0.8571428571428571, 'f1-score': 0.923076923076923, 'support': 70}, '22': {'precision': 0.9459459459459459, 'recall': 1.0, 'f1-score': 0.9722222222222222, 'support': 70}, '23': {'precision': 0.9428571428571428, 'recall': 0.9428571428571428, 'f1-score': 0.9428571428571428, 'support': 70}, '24': {'precision': 0.9722222222222222, 'recall': 1.0, 'f1-score': 0.9859154929577464, 'support': 70}, '25': {'precision': 1.0, 'recall': 0.9714285714285714, 'f1-score': 0.9855072463768115, 'support': 70}, '26': {'precision': 0.8333333333333334, 'recall': 0.9285714285714286, 'f1-score': 0.8783783783783784, 'support': 70}, '27': {'precision': 0.9583333333333334, 'recall': 0.9857142857142858, 'f1-score': 0.971830985915493, 'support': 70}, '28': {'precision': 1.0, 'recall': 0.9714285714285714, 'f1-score': 0.9855072463768115, 'support': 70}, '2l': {'precision': 0.9859154929577465, 'recall': 1.0, 'f1-score': 0.9929078014184397, 'support': 70}, '4': {'precision': 1.0, 'recall': 0.9428571428571428, 'f1-score': 0.9705882352941176, 'support': 70}, '41': {'precision': 0.9848484848484849, 'recall': 0.9285714285714286, 'f1-score': 0.9558823529411765, 'support': 70}, '42': {'precision': 0.9130434782608695, 'recall': 0.9, 'f1-score': 0.9064748201438848, 'support': 70}, '43': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 70}, '44': {'precision': 0.85, 'recall': 0.9714285714285714, 'f1-score': 0.9066666666666667, 'support': 70}, '45': {'precision': 0.9452054794520548, 'recall': 0.9857142857142858, 'f1-score': 0.9650349650349651, 'support': 70}, '46l': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 70}, '46r': {'precision': 0.9705882352941176, 'recall': 0.9428571428571428, 'f1-score': 0.9565217391304348, 'support': 70}, '5': {'precision': 0.9210526315789473, 'recall': 1.0, 'f1-score': 0.958904109589041, 'support': 70}, '6': {'precision': 1.0, 'recall': 0.9714285714285714, 'f1-score': 0.9855072463768115, 'support': 70}, '7': {'precision': 0.9692307692307692, 'recall': 0.9, 'f1-score': 0.9333333333333333, 'support': 70}, '9': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 70}, 'baseline_sitting': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 80}, 'eating': {'precision': 0.9871794871794872, 'recall': 0.9625, 'f1-score': 0.9746835443037976, 'support': 80}, 'speaking': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 80}, 'accuracy': 0.9639004149377594, 'macro avg': {'precision': 0.9650597992768721, 'recall': 0.9636029411764705, 'f1-score': 0.9635355854797204, 'support': 2410}, 'weighted avg': {'precision': 0.9654415423862035, 'recall': 0.9639004149377594, 'f1-score': 0.9638844518194075, 'support': 2410}}\n","------------------------ Fold 2/5 ------------------------\n","(9640, 100, 12) (2410, 100, 12) (9640, 34) (2410, 34)\n","Model loaded succesfully!\n","{'1': {'precision': 0.9577464788732394, 'recall': 0.9714285714285714, 'f1-score': 0.9645390070921985, 'support': 70}, '10': {'precision': 0.9545454545454546, 'recall': 0.9, 'f1-score': 0.9264705882352942, 'support': 70}, '11': {'precision': 0.9552238805970149, 'recall': 0.9142857142857143, 'f1-score': 0.9343065693430657, 'support': 70}, '12': {'precision': 0.9315068493150684, 'recall': 0.9714285714285714, 'f1-score': 0.9510489510489512, 'support': 70}, '13': {'precision': 0.918918918918919, 'recall': 0.9714285714285714, 'f1-score': 0.9444444444444445, 'support': 70}, '14': {'precision': 1.0, 'recall': 0.9285714285714286, 'f1-score': 0.962962962962963, 'support': 70}, '15': {'precision': 0.8888888888888888, 'recall': 0.9142857142857143, 'f1-score': 0.9014084507042254, 'support': 70}, '16': {'precision': 0.9130434782608695, 'recall': 0.9, 'f1-score': 0.9064748201438848, 'support': 70}, '17': {'precision': 0.8933333333333333, 'recall': 0.9571428571428572, 'f1-score': 0.9241379310344828, 'support': 70}, '18': {'precision': 0.9850746268656716, 'recall': 0.9428571428571428, 'f1-score': 0.9635036496350364, 'support': 70}, '20': {'precision': 0.9696969696969697, 'recall': 0.9142857142857143, 'f1-score': 0.9411764705882354, 'support': 70}, '22': {'precision': 0.918918918918919, 'recall': 0.9714285714285714, 'f1-score': 0.9444444444444445, 'support': 70}, '23': {'precision': 0.9722222222222222, 'recall': 1.0, 'f1-score': 0.9859154929577464, 'support': 70}, '24': {'precision': 0.8767123287671232, 'recall': 0.9142857142857143, 'f1-score': 0.8951048951048951, 'support': 70}, '25': {'precision': 0.9857142857142858, 'recall': 0.9857142857142858, 'f1-score': 0.9857142857142858, 'support': 70}, '26': {'precision': 0.8048780487804879, 'recall': 0.9428571428571428, 'f1-score': 0.868421052631579, 'support': 70}, '27': {'precision': 0.9722222222222222, 'recall': 1.0, 'f1-score': 0.9859154929577464, 'support': 70}, '28': {'precision': 0.8513513513513513, 'recall': 0.9, 'f1-score': 0.875, 'support': 70}, '2l': {'precision': 1.0, 'recall': 0.9857142857142858, 'f1-score': 0.9928057553956835, 'support': 70}, '4': {'precision': 0.9154929577464789, 'recall': 0.9285714285714286, 'f1-score': 0.921985815602837, 'support': 70}, '41': {'precision': 0.8888888888888888, 'recall': 0.8, 'f1-score': 0.8421052631578948, 'support': 70}, '42': {'precision': 1.0, 'recall': 0.9571428571428572, 'f1-score': 0.9781021897810218, 'support': 70}, '43': {'precision': 0.9583333333333334, 'recall': 0.9857142857142858, 'f1-score': 0.971830985915493, 'support': 70}, '44': {'precision': 0.927536231884058, 'recall': 0.9142857142857143, 'f1-score': 0.920863309352518, 'support': 70}, '45': {'precision': 0.9315068493150684, 'recall': 0.9714285714285714, 'f1-score': 0.9510489510489512, 'support': 70}, '46l': {'precision': 0.8985507246376812, 'recall': 0.8857142857142857, 'f1-score': 0.8920863309352518, 'support': 70}, '46r': {'precision': 0.984375, 'recall': 0.9, 'f1-score': 0.9402985074626866, 'support': 70}, '5': {'precision': 0.9014084507042254, 'recall': 0.9142857142857143, 'f1-score': 0.9078014184397163, 'support': 70}, '6': {'precision': 0.971830985915493, 'recall': 0.9857142857142858, 'f1-score': 0.9787234042553192, 'support': 70}, '7': {'precision': 0.8857142857142857, 'recall': 0.8857142857142857, 'f1-score': 0.8857142857142857, 'support': 70}, '9': {'precision': 0.9523809523809523, 'recall': 0.8571428571428571, 'f1-score': 0.9022556390977443, 'support': 70}, 'baseline_sitting': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 80}, 'eating': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 80}, 'speaking': {'precision': 1.0, 'recall': 0.95, 'f1-score': 0.9743589743589743, 'support': 80}, 'accuracy': 0.9394190871369295, 'macro avg': {'precision': 0.9401769681703678, 'recall': 0.9388655462184874, 'f1-score': 0.9388520688106429, 'support': 2410}, 'weighted avg': {'precision': 0.94092165321389, 'recall': 0.9394190871369295, 'f1-score': 0.9395068520800497, 'support': 2410}}\n","------------------------ Fold 3/5 ------------------------\n","(9640, 100, 12) (2410, 100, 12) (9640, 34) (2410, 34)\n","Model loaded succesfully!\n","{'1': {'precision': 0.9855072463768116, 'recall': 0.9714285714285714, 'f1-score': 0.9784172661870504, 'support': 70}, '10': {'precision': 0.9411764705882353, 'recall': 0.9142857142857143, 'f1-score': 0.9275362318840579, 'support': 70}, '11': {'precision': 0.9571428571428572, 'recall': 0.9571428571428572, 'f1-score': 0.9571428571428572, 'support': 70}, '12': {'precision': 0.8974358974358975, 'recall': 1.0, 'f1-score': 0.945945945945946, 'support': 70}, '13': {'precision': 0.9850746268656716, 'recall': 0.9428571428571428, 'f1-score': 0.9635036496350364, 'support': 70}, '14': {'precision': 0.9850746268656716, 'recall': 0.9428571428571428, 'f1-score': 0.9635036496350364, 'support': 70}, '15': {'precision': 0.8831168831168831, 'recall': 0.9714285714285714, 'f1-score': 0.9251700680272108, 'support': 70}, '16': {'precision': 0.9692307692307692, 'recall': 0.9, 'f1-score': 0.9333333333333333, 'support': 70}, '17': {'precision': 0.9436619718309859, 'recall': 0.9571428571428572, 'f1-score': 0.9503546099290779, 'support': 70}, '18': {'precision': 0.9859154929577465, 'recall': 1.0, 'f1-score': 0.9929078014184397, 'support': 70}, '20': {'precision': 0.9571428571428572, 'recall': 0.9571428571428572, 'f1-score': 0.9571428571428572, 'support': 70}, '22': {'precision': 0.9242424242424242, 'recall': 0.8714285714285714, 'f1-score': 0.8970588235294117, 'support': 70}, '23': {'precision': 1.0, 'recall': 0.9285714285714286, 'f1-score': 0.962962962962963, 'support': 70}, '24': {'precision': 0.868421052631579, 'recall': 0.9428571428571428, 'f1-score': 0.904109589041096, 'support': 70}, '25': {'precision': 0.9857142857142858, 'recall': 0.9857142857142858, 'f1-score': 0.9857142857142858, 'support': 70}, '26': {'precision': 0.9538461538461539, 'recall': 0.8857142857142857, 'f1-score': 0.9185185185185185, 'support': 70}, '27': {'precision': 0.8860759493670886, 'recall': 1.0, 'f1-score': 0.9395973154362416, 'support': 70}, '28': {'precision': 0.9848484848484849, 'recall': 0.9285714285714286, 'f1-score': 0.9558823529411765, 'support': 70}, '2l': {'precision': 0.9859154929577465, 'recall': 1.0, 'f1-score': 0.9929078014184397, 'support': 70}, '4': {'precision': 0.9848484848484849, 'recall': 0.9285714285714286, 'f1-score': 0.9558823529411765, 'support': 70}, '41': {'precision': 0.9444444444444444, 'recall': 0.9714285714285714, 'f1-score': 0.9577464788732395, 'support': 70}, '42': {'precision': 1.0, 'recall': 0.9285714285714286, 'f1-score': 0.962962962962963, 'support': 70}, '43': {'precision': 1.0, 'recall': 0.9, 'f1-score': 0.9473684210526316, 'support': 70}, '44': {'precision': 0.9315068493150684, 'recall': 0.9714285714285714, 'f1-score': 0.9510489510489512, 'support': 70}, '45': {'precision': 0.9333333333333333, 'recall': 1.0, 'f1-score': 0.9655172413793104, 'support': 70}, '46l': {'precision': 0.9285714285714286, 'recall': 0.9285714285714286, 'f1-score': 0.9285714285714286, 'support': 70}, '46r': {'precision': 0.9848484848484849, 'recall': 0.9285714285714286, 'f1-score': 0.9558823529411765, 'support': 70}, '5': {'precision': 0.8648648648648649, 'recall': 0.9142857142857143, 'f1-score': 0.888888888888889, 'support': 70}, '6': {'precision': 0.9701492537313433, 'recall': 0.9285714285714286, 'f1-score': 0.948905109489051, 'support': 70}, '7': {'precision': 0.9857142857142858, 'recall': 0.9857142857142858, 'f1-score': 0.9857142857142858, 'support': 70}, '9': {'precision': 0.8947368421052632, 'recall': 0.9714285714285714, 'f1-score': 0.9315068493150684, 'support': 70}, 'baseline_sitting': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 80}, 'eating': {'precision': 0.963855421686747, 'recall': 1.0, 'f1-score': 0.9815950920245399, 'support': 80}, 'speaking': {'precision': 1.0, 'recall': 0.9875, 'f1-score': 0.9937106918238994, 'support': 80}, 'accuracy': 0.9535269709543569, 'macro avg': {'precision': 0.9548946246066441, 'recall': 0.9529936974789914, 'f1-score': 0.9531473831432249, 'support': 2410}, 'weighted avg': {'precision': 0.9553061248052616, 'recall': 0.9535269709543569, 'f1-score': 0.9536281451117677, 'support': 2410}}\n","------------------------ Fold 4/5 ------------------------\n","(9640, 100, 12) (2410, 100, 12) (9640, 34) (2410, 34)\n","Model loaded succesfully!\n","{'1': {'precision': 1.0, 'recall': 0.9428571428571428, 'f1-score': 0.9705882352941176, 'support': 70}, '10': {'precision': 0.9846153846153847, 'recall': 0.9142857142857143, 'f1-score': 0.9481481481481482, 'support': 70}, '11': {'precision': 0.9714285714285714, 'recall': 0.9714285714285714, 'f1-score': 0.9714285714285714, 'support': 70}, '12': {'precision': 1.0, 'recall': 0.9857142857142858, 'f1-score': 0.9928057553956835, 'support': 70}, '13': {'precision': 1.0, 'recall': 0.9857142857142858, 'f1-score': 0.9928057553956835, 'support': 70}, '14': {'precision': 0.958904109589041, 'recall': 1.0, 'f1-score': 0.9790209790209791, 'support': 70}, '15': {'precision': 0.9583333333333334, 'recall': 0.9857142857142858, 'f1-score': 0.971830985915493, 'support': 70}, '16': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 70}, '17': {'precision': 1.0, 'recall': 0.9857142857142858, 'f1-score': 0.9928057553956835, 'support': 70}, '18': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 70}, '20': {'precision': 0.88, 'recall': 0.9428571428571428, 'f1-score': 0.9103448275862068, 'support': 70}, '22': {'precision': 0.9324324324324325, 'recall': 0.9857142857142858, 'f1-score': 0.9583333333333333, 'support': 70}, '23': {'precision': 0.9078947368421053, 'recall': 0.9857142857142858, 'f1-score': 0.9452054794520548, 'support': 70}, '24': {'precision': 0.9859154929577465, 'recall': 1.0, 'f1-score': 0.9929078014184397, 'support': 70}, '25': {'precision': 0.9565217391304348, 'recall': 0.9428571428571428, 'f1-score': 0.9496402877697843, 'support': 70}, '26': {'precision': 0.9850746268656716, 'recall': 0.9428571428571428, 'f1-score': 0.9635036496350364, 'support': 70}, '27': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 70}, '28': {'precision': 0.9850746268656716, 'recall': 0.9428571428571428, 'f1-score': 0.9635036496350364, 'support': 70}, '2l': {'precision': 0.9857142857142858, 'recall': 0.9857142857142858, 'f1-score': 0.9857142857142858, 'support': 70}, '4': {'precision': 0.9859154929577465, 'recall': 1.0, 'f1-score': 0.9929078014184397, 'support': 70}, '41': {'precision': 1.0, 'recall': 0.9428571428571428, 'f1-score': 0.9705882352941176, 'support': 70}, '42': {'precision': 0.9857142857142858, 'recall': 0.9857142857142858, 'f1-score': 0.9857142857142858, 'support': 70}, '43': {'precision': 0.9459459459459459, 'recall': 1.0, 'f1-score': 0.9722222222222222, 'support': 70}, '44': {'precision': 1.0, 'recall': 0.9428571428571428, 'f1-score': 0.9705882352941176, 'support': 70}, '45': {'precision': 0.9850746268656716, 'recall': 0.9428571428571428, 'f1-score': 0.9635036496350364, 'support': 70}, '46l': {'precision': 1.0, 'recall': 0.9571428571428572, 'f1-score': 0.9781021897810218, 'support': 70}, '46r': {'precision': 0.9583333333333334, 'recall': 0.9857142857142858, 'f1-score': 0.971830985915493, 'support': 70}, '5': {'precision': 0.958904109589041, 'recall': 1.0, 'f1-score': 0.9790209790209791, 'support': 70}, '6': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 70}, '7': {'precision': 0.9444444444444444, 'recall': 0.9714285714285714, 'f1-score': 0.9577464788732395, 'support': 70}, '9': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 70}, 'baseline_sitting': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 80}, 'eating': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 80}, 'speaking': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 80}, 'accuracy': 0.9775933609958506, 'macro avg': {'precision': 0.9781247523125042, 'recall': 0.9773109243697479, 'f1-score': 0.9773768401090438, 'support': 2410}, 'weighted avg': {'precision': 0.9783970583003155, 'recall': 0.9775933609958506, 'f1-score': 0.9776584562072714, 'support': 2410}}\n","------------------------ Fold 5/5 ------------------------\n","(9640, 100, 12) (2410, 100, 12) (9640, 34) (2410, 34)\n","Model loaded succesfully!\n","{'1': {'precision': 0.9324324324324325, 'recall': 0.9857142857142858, 'f1-score': 0.9583333333333333, 'support': 70}, '10': {'precision': 0.8481012658227848, 'recall': 0.9571428571428572, 'f1-score': 0.8993288590604026, 'support': 70}, '11': {'precision': 0.8125, 'recall': 0.9285714285714286, 'f1-score': 0.8666666666666666, 'support': 70}, '12': {'precision': 0.9859154929577465, 'recall': 1.0, 'f1-score': 0.9929078014184397, 'support': 70}, '13': {'precision': 0.8947368421052632, 'recall': 0.9714285714285714, 'f1-score': 0.9315068493150684, 'support': 70}, '14': {'precision': 0.967741935483871, 'recall': 0.8571428571428571, 'f1-score': 0.909090909090909, 'support': 70}, '15': {'precision': 0.9402985074626866, 'recall': 0.9, 'f1-score': 0.9197080291970803, 'support': 70}, '16': {'precision': 0.8947368421052632, 'recall': 0.9714285714285714, 'f1-score': 0.9315068493150684, 'support': 70}, '17': {'precision': 0.9552238805970149, 'recall': 0.9142857142857143, 'f1-score': 0.9343065693430657, 'support': 70}, '18': {'precision': 0.9859154929577465, 'recall': 1.0, 'f1-score': 0.9929078014184397, 'support': 70}, '20': {'precision': 0.9384615384615385, 'recall': 0.8714285714285714, 'f1-score': 0.9037037037037037, 'support': 70}, '22': {'precision': 0.921875, 'recall': 0.8428571428571429, 'f1-score': 0.880597014925373, 'support': 70}, '23': {'precision': 0.9459459459459459, 'recall': 1.0, 'f1-score': 0.9722222222222222, 'support': 70}, '24': {'precision': 0.8611111111111112, 'recall': 0.8857142857142857, 'f1-score': 0.8732394366197184, 'support': 70}, '25': {'precision': 1.0, 'recall': 0.8714285714285714, 'f1-score': 0.9312977099236641, 'support': 70}, '26': {'precision': 0.9444444444444444, 'recall': 0.9714285714285714, 'f1-score': 0.9577464788732395, 'support': 70}, '27': {'precision': 1.0, 'recall': 0.9857142857142858, 'f1-score': 0.9928057553956835, 'support': 70}, '28': {'precision': 0.9692307692307692, 'recall': 0.9, 'f1-score': 0.9333333333333333, 'support': 70}, '2l': {'precision': 0.9857142857142858, 'recall': 0.9857142857142858, 'f1-score': 0.9857142857142858, 'support': 70}, '4': {'precision': 0.8970588235294118, 'recall': 0.8714285714285714, 'f1-score': 0.8840579710144928, 'support': 70}, '41': {'precision': 0.92, 'recall': 0.9857142857142858, 'f1-score': 0.9517241379310346, 'support': 70}, '42': {'precision': 0.9253731343283582, 'recall': 0.8857142857142857, 'f1-score': 0.9051094890510949, 'support': 70}, '43': {'precision': 0.9857142857142858, 'recall': 0.9857142857142858, 'f1-score': 0.9857142857142858, 'support': 70}, '44': {'precision': 0.9857142857142858, 'recall': 0.9857142857142858, 'f1-score': 0.9857142857142858, 'support': 70}, '45': {'precision': 0.9583333333333334, 'recall': 0.9857142857142858, 'f1-score': 0.971830985915493, 'support': 70}, '46l': {'precision': 0.9696969696969697, 'recall': 0.9142857142857143, 'f1-score': 0.9411764705882354, 'support': 70}, '46r': {'precision': 1.0, 'recall': 0.9857142857142858, 'f1-score': 0.9928057553956835, 'support': 70}, '5': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 70}, '6': {'precision': 0.9852941176470589, 'recall': 0.9571428571428572, 'f1-score': 0.9710144927536232, 'support': 70}, '7': {'precision': 0.8947368421052632, 'recall': 0.9714285714285714, 'f1-score': 0.9315068493150684, 'support': 70}, '9': {'precision': 0.9076923076923077, 'recall': 0.8428571428571429, 'f1-score': 0.8740740740740741, 'support': 70}, 'baseline_sitting': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 80}, 'eating': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 80}, 'speaking': {'precision': 1.0, 'recall': 0.9875, 'f1-score': 0.9937106918238994, 'support': 80}, 'accuracy': 0.9464730290456431, 'macro avg': {'precision': 0.9474705848998288, 'recall': 0.9458508403361343, 'f1-score': 0.9457459734753224, 'support': 2410}, 'weighted avg': {'precision': 0.9481244780338558, 'recall': 0.9464730290456431, 'f1-score': 0.9463952380869324, 'support': 2410}}\n","5-fold Cross Validation Accuracy: 0.9561825726141079\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r0W8jF82NQDe","executionInfo":{"status":"ok","timestamp":1619984057918,"user_tz":-330,"elapsed":4490,"user":{"displayName":"Sejal Bhalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd83T8nE5o6zGLINWWUfr_S_8fE_h_SM_LXr0WGQ=s64","userId":"12680971253671894594"}},"outputId":"d28d4427-a25f-4b6f-be1c-12836f65004a"},"source":["y_pred = model.predict(X_test)\n","print(classification_report(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), target_names = labels))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","          au       1.00      1.00      1.00      2170\n","       other       1.00      1.00      1.00       240\n","\n","    accuracy                           1.00      2410\n","   macro avg       1.00      1.00      1.00      2410\n","weighted avg       1.00      1.00      1.00      2410\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"ymJY80ErNvQl","executionInfo":{"status":"ok","timestamp":1619984065335,"user_tz":-330,"elapsed":1233,"user":{"displayName":"Sejal Bhalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggd83T8nE5o6zGLINWWUfr_S_8fE_h_SM_LXr0WGQ=s64","userId":"12680971253671894594"}},"outputId":"24efe8f2-89a5-4d9b-df77-6c2cb6b9c513"},"source":["sns.heatmap(confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1)), xticklabels=labels, yticklabels=labels)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7fe8fa42e490>"]},"metadata":{"tags":[]},"execution_count":134},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"_impGK6MON2J"},"source":[""],"execution_count":null,"outputs":[]}]}